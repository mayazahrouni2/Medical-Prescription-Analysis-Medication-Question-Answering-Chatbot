{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "ZSFKVdVCcUSD",
        "outputId": "5d9ce659-dff2-4e98-82f3-d80f76293c18"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "# URL de ton API OCR\n",
        "url = \"https://19fe840519fb.ngrok-free.app/ocr\"\n",
        "\n",
        "# Chemin de l'image Ã  envoyer\n",
        "image_path = \"/content/3.jpg\"   # ou Desktop/3.jpeg si ton script est sur le bureau\n",
        "\n",
        "# Ouvrir lâ€™image\n",
        "with open(image_path, \"rb\") as f:\n",
        "    files = {\"image\": (image_path, f, \"image/jpeg\")}\n",
        "    response = requests.post(url, files=files)\n",
        "\n",
        "# Affichage du rÃ©sultat\n",
        "print(\"Status:\", response.status_code)\n",
        "print(\"RÃ©ponse OCR:\", response.json())\n",
        "\n",
        "with open(image_path, \"rb\") as f:\n",
        "    data = {\"image\": (image_path, f, \"/content/3.jpg\")}\n",
        "    resp = requests.post(url, files=data)\n",
        "\n",
        "print(resp.json()[\"text\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ap2F8b1c33D"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "url = \"https://19fe840519fb.ngrok-free.app/ocr\"\n",
        "image_path = \"/content/4.jpg\"\n",
        "\n",
        "with open(image_path, \"rb\") as f:\n",
        "    response = requests.post(\n",
        "        url,\n",
        "        files={\"image\": (image_path, f, \"image/jpeg\")}\n",
        "    )\n",
        "\n",
        "data = response.json()\n",
        "\n",
        "print(\"--- TEXT EXACTEMENT COMME SWAGGER ---\")\n",
        "print(data[\"text\"])                 # mÃªme rÃ©sultat que Swagger\n",
        "print(\"--- JSON complet ---\")\n",
        "print(data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ge4P8X8jhg9n"
      },
      "source": [
        "Mon assistant :\n",
        "\n",
        "corrige OCR\n",
        "\n",
        "identifie les mÃ©dicaments\n",
        "\n",
        "gÃ©nÃ¨re leur fiche mÃ©dicale (option B)\n",
        "\n",
        "fait une recherche FAISS intelligente\n",
        "\n",
        "gÃ©nÃ¨re une rÃ©ponse mÃ©dicale experte via Mistral\n",
        "\n",
        "ğŸ”¥ j'ai maintenant un assistant mÃ©dical IA complet, gratuit, open-source, sans API, avec expert OCR + RAG enrichi."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOkTpJnvk6Ii"
      },
      "source": [
        "                      (ancien code)\n",
        "        OCR TEXT  â”€â”€â–º  LLM extraction  â”€â”€â–º  DRUGS CORRIGÃ‰S\n",
        "                                â”‚\n",
        "                                â–¼\n",
        "                          Matching dataset (FAISS)\n",
        "                                â”‚\n",
        "            DRUG FOUND? â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â–º NO â†’ ADD TO DATASET + REBUILD EMBEDDINGS\n",
        "                                â–¼\n",
        "                            DRUG LIST FINAL\n",
        "                                â”‚\n",
        "                                â–¼\n",
        "                  RAG (retrieved meds only) + llM\n",
        "                                â”‚\n",
        "                                â–¼\n",
        "                    INTERACTION MÃ‰DICALE INTELLIGENTE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJXNjLMzEUK5",
        "outputId": "ca4af0e1-eeac-4ddc-952a-f7bab3c61bc7"
      },
      "outputs": [],
      "source": [
        "!pip uninstall -y transformers sentence-transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ft3W7vc7E7AV",
        "outputId": "b4e76cf4-eb33-4d17-ee06-2448b988886e"
      },
      "outputs": [],
      "source": [
        "!pip install transformers==4.30.0\n",
        "!pip install sentence-transformers==2.2.2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuDploNFFWQ_",
        "outputId": "25692f77-24de-4e18-dd91-5138a44493c3"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade huggingface_hub\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w88t0533FcZb",
        "outputId": "5ab13686-db06-4a0a-eedb-ba13b8d47f5d"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade sentence-transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install httpx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install openai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import httpx\n",
        "import json\n",
        "from openai import OpenAI\n",
        "import re\n",
        "\n",
        "# --- Connexion API TokenFactory ---\n",
        "esprit_api_key = \"sk-e376096028c847389e18f6d1f650be93\"\n",
        "\n",
        "http_client = httpx.Client(verify=False)\n",
        "client = OpenAI(\n",
        "    api_key=esprit_api_key,\n",
        "    base_url=\"https://tokenfactory.esprit.tn/api\",\n",
        "    http_client=http_client\n",
        ")\n",
        "\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# ğŸ›¡ï¸ 1. JSON Cleaner : retire le markdown, rÃ©pare virgules\n",
        "# ------------------------------------------------------\n",
        "def clean_json_output(text):\n",
        "    text = text.strip()\n",
        "\n",
        "    # Enlever Ã©ventuels ```json ... ```\n",
        "    text = re.sub(r\"```json\", \"\", text, flags=re.IGNORECASE).strip()\n",
        "    text = re.sub(r\"```\", \"\", text).strip()\n",
        "\n",
        "    # Retirer trailing commas avant les }\n",
        "    text = re.sub(r\",\\s*}\", \"}\", text)\n",
        "    text = re.sub(r\",\\s*]\", \"]\", text)\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# ğŸ›¡ï¸ 2. VALIDATION DES CHAMPS\n",
        "# ------------------------------------------------------\n",
        "def validate_medical_card(card: dict, drug_name: str):\n",
        "    \"\"\"\n",
        "    VÃ©rifie que la carte contient bien tous les champs requis.\n",
        "    Corrige les types si nÃ©cessaire.\n",
        "    \"\"\"\n",
        "\n",
        "    template = {\n",
        "        \"drug\": drug_name,\n",
        "        \"class\": \"\",\n",
        "        \"indications\": [],\n",
        "        \"mechanism\": \"\",\n",
        "        \"dosage\": \"\",\n",
        "        \"side_effects\": [],\n",
        "        \"contraindications\": [],\n",
        "        \"interactions\": []\n",
        "    }\n",
        "\n",
        "    for key, default in template.items():\n",
        "\n",
        "        if key not in card:\n",
        "            card[key] = default\n",
        "            continue\n",
        "\n",
        "        # Assurer les types corrects\n",
        "        if isinstance(default, list) and not isinstance(card[key], list):\n",
        "            card[key] = [card[key]] if card[key] else []\n",
        "\n",
        "        if isinstance(default, str) and not isinstance(card[key], str):\n",
        "            card[key] = str(card[key])\n",
        "\n",
        "    return card\n",
        "\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# ğŸ§  3. FONCTION PRINCIPALE : ULTRA-ROBUSTE\n",
        "# ------------------------------------------------------\n",
        "def generate_medical_card(drug: str):\n",
        "    \"\"\"\n",
        "    GÃ©nÃ¨re une carte mÃ©dicale fiable, nettoyÃ©e et validÃ©e.\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "Tu es un expert mÃ©dical. Ta mission : gÃ©nÃ©rer UNE SEULE fiche mÃ©dicale fiable\n",
        "pour le mÃ©dicament suivant : \"{drug}\".\n",
        "\n",
        "RÃˆGLES STRICTES :\n",
        "- Tu rÃ©ponds EXCLUSIVEMENT en JSON valide.\n",
        "- Pas de texte avant ou aprÃ¨s le JSON.\n",
        "- Remplis seulement ce que tu connais avec certitude.\n",
        "- Si tu n'es pas sÃ»r, mets une chaÃ®ne vide \"\" ou une liste vide [].\n",
        "\n",
        "FORMAT EXACT Ã€ RESPECTER :\n",
        "{{\n",
        "  \"drug\": \"{drug}\",\n",
        "  \"class\": \"\",\n",
        "  \"indications\": [],\n",
        "  \"mechanism\": \"\",\n",
        "  \"dosage\": \"\",\n",
        "  \"side_effects\": [],\n",
        "  \"contraindications\": [],\n",
        "  \"interactions\": []\n",
        "}}\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"hosted_vllm/Llama-3.1-70B-Instruct\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"Assistant mÃ©dical strict, factuel, sans spÃ©culation.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=0.15,   # ğŸ”¥ plus basse â†’ moins d'hallucinations\n",
        "            max_tokens=600\n",
        "        )\n",
        "\n",
        "        raw = response.choices[0].message.content.strip()\n",
        "\n",
        "        # --- nettoyage JSON\n",
        "        cleaned = clean_json_output(raw)\n",
        "\n",
        "        try:\n",
        "            parsed = json.loads(cleaned)\n",
        "        except Exception:\n",
        "            print(\"âš  JSON invalide. Sortie brute :\")\n",
        "            print(raw)\n",
        "            return {\"drug\": drug, \"error\": \"Invalid JSON\", \"raw\": raw}\n",
        "\n",
        "        # Validation-type + complÃ©tion des champs\n",
        "        validated = validate_medical_card(parsed, drug)\n",
        "\n",
        "        return validated\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âš  Erreur gÃ©nÃ©ration carte mÃ©dicale pour {drug}: {e}\")\n",
        "        return {\"drug\": drug, \"error\": str(e)}\n",
        "card = generate_medical_card(\"Paracetamol\")\n",
        "print(json.dumps(card, indent=2, ensure_ascii=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "import json\n",
        "import httpx\n",
        "from openai import OpenAI\n",
        "\n",
        "# --- Connexion Ã  lâ€™API TokenFactory --- \n",
        "# Utilisation de httpx pour la connexion HTTP avec TokenFactory (Llama)\n",
        "esprit_api_key = \"sk-e376096028c847389e18f6d1f650be93\"  # Remplacez par votre propre clÃ© API ESPRIT\n",
        "\n",
        "# --- Connexion Ã  lâ€™API ESPRIT ---\n",
        "http_client = httpx.Client(verify=False)\n",
        "client = OpenAI(\n",
        "    api_key=esprit_api_key,\n",
        "    base_url=\"https://tokenfactory.esprit.tn/api\",\n",
        "    http_client=http_client\n",
        ")\n",
        "\n",
        "\n",
        "def correct_medicine_name_with_llama(med_name, dosage, duration):\n",
        "    \"\"\"\n",
        "    Appelle llama pour valider ou corriger un nom de mÃ©dicament,\n",
        "    en utilisant le dosage et la durÃ©e comme contexte pour plus de prÃ©cision.\n",
        "    \"\"\"\n",
        "    # Utilisation de f-strings pour inclure les dÃ©tails contextuels\n",
        "    prompt = f\"\"\"\n",
        "    Vous Ãªtes un expert en pharmacie et votre unique tÃ¢che est de valider le nom d'un mÃ©dicament, en utilisant le dosage et la durÃ©e comme contexte pour garantir la prÃ©cision.\n",
        "    **RÃ©pondez uniquement avec le nom du mÃ©dicament corrigÃ© ou original, sans aucune explication ni ponctuation supplÃ©mentaire.**\n",
        "\n",
        "    Informations de l'ordonnance:\n",
        "    - Nom extrait (potentiellement erronÃ©) : {med_name}\n",
        "    - Posologie/Instructions : {dosage}\n",
        "    - DurÃ©e : {duration}\n",
        "\n",
        "    Correction :\n",
        "    Si le nom est mal orthographiÃ© ou peu clair, proposez la correction la plus probable et pertinente dans ce contexte. Par exemple, si le nom est 'PaniD' et le dosage est '40mg before meals', la correction appropriÃ©e est 'Pan-D' (ou Pantoprazole). Si le nom est correct, laissez-le tel quel.\n",
        "\n",
        "    Nom du mÃ©dicament corrigÃ© ou confirmÃ© :\n",
        "    \"\"\"\n",
        "\n",
        "    # Envoi de la requÃªte via l'API ESPRIT\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"hosted_vllm/Llama-3.1-70B-Instruct\",\n",
        "            messages=[ \n",
        "                {\"role\": \"system\", \"content\": \"Tu es un assistant mÃ©dical et administratif utile et concis.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=0.4,\n",
        "            max_tokens=700,\n",
        "            top_p=0.9\n",
        "        )\n",
        "\n",
        "        # Log de la rÃ©ponse pour inspecter sa structure\n",
        "        print(\"RÃ©ponse complÃ¨te de l'API:\", response)\n",
        "\n",
        "        # AccÃ©der Ã  la rÃ©ponse en extrayant les choix correctement\n",
        "        content = response.choices[0].message.content  # Utiliser la bonne syntaxe pour accÃ©der au contenu\n",
        "        return content\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Erreur lors de la correction du mÃ©dicament '{med_name}' : {e}\")\n",
        "        return {\"drug\": med_name, \"error\": str(e)}\n",
        "\n",
        "\n",
        "def extract_and_correct_meds_with_llama(ocr_text):\n",
        "    \"\"\"\n",
        "    Appelle llama pour extraire les mÃ©dicaments, la posologie et la durÃ©e\n",
        "    d'un texte OCR. ConcentrÃ© sur l'extraction brute et le format JSON strict.\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    Votre tÃ¢che est d'analyser le texte OCR d'une ordonnance mÃ©dicale et d'**extraire tous les mÃ©dicaments identifiables, leur posologie et leur durÃ©e**.\n",
        "    Le texte peut contenir des erreurs d'orthographe ou de fusion. Identifiez le **nom de mÃ©dicament le plus probable** Ã  partir du contexte.\n",
        "    **N'effectuez AUCUNE correction d'orthographe ni de validation pharmaceutique.** Indiquez seulement ce que vous trouvez.\n",
        "    **Laissez le champ 'dosage' et 'duration' aussi bruts que possible** pour capturer toutes les informations contextuelles pertinentes.\n",
        "\n",
        "    Vous DEVEZ sortir une rÃ©ponse **stricte** au format JSON suivant :\n",
        "\n",
        "    [\n",
        "        {{\"drug\": \"Nom du mÃ©dicament extrait\", \"dosage\": \"Informations de posologie brutes (ex: 625mg x5day, 40mg before meals)\", \"duration\": \"Informations de durÃ©e brutes (ex: 5days, 1week)\"}}\n",
        "    ]\n",
        "\n",
        "    TEXT OCR :\n",
        "    {ocr_text}\n",
        "    \"\"\"\n",
        "\n",
        "    # Envoi de la requÃªte via l'API ESPRIT\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"hosted_vllm/Llama-3.1-70B-Instruct\",\n",
        "            messages=[ \n",
        "                {\"role\": \"system\", \"content\": \"Tu es un assistant mÃ©dical et administratif utile et concis.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=0.4,\n",
        "            max_tokens=700,\n",
        "            top_p=0.9\n",
        "        )\n",
        "\n",
        "        # Log de la rÃ©ponse pour inspecter sa structure\n",
        "        print(\"RÃ©ponse complÃ¨te de l'API:\", response)\n",
        "\n",
        "        # AccÃ©der Ã  la rÃ©ponse en extrayant le contenu JSON depuis la rÃ©ponse de l'API\n",
        "        response_text = response.choices[0].message.content  # Utiliser la bonne syntaxe pour accÃ©der au contenu\n",
        "        print(\"RÃ©ponse textuelle extraite :\", response_text)\n",
        "\n",
        "        # VÃ©rifier si la rÃ©ponse est bien un JSON valide\n",
        "        try:\n",
        "            extracted_meds = json.loads(response_text)  # Convertir la chaÃ®ne JSON en un objet Python\n",
        "        except json.JSONDecodeError as json_err:\n",
        "            print(f\"âš ï¸ Erreur lors du dÃ©codage JSON : {json_err}\")\n",
        "            return {\"error\": \"RÃ©ponse API invalide\"}\n",
        "\n",
        "        return extracted_meds\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Erreur lors de l'extraction et correction des mÃ©dicaments : {e}\")\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "\n",
        "# --- EXEMPLE D'UTILISATION ---\n",
        "ocr_text_input = \"Rx Tab Auguentin 625mg x5day Enzoflarn 5days PaniD 40mg before meals Hexigel gum paste 1week\"\n",
        "\n",
        "# Extrait et corrige les mÃ©dicaments extraits via Llama\n",
        "extracted_meds = extract_and_correct_meds_with_llama(ocr_text_input)\n",
        "\n",
        "# VÃ©rifier si la rÃ©ponse est bien un tableau de mÃ©dicaments\n",
        "if isinstance(extracted_meds, list):\n",
        "    # Correction supplÃ©mentaire avec Llama si nÃ©cessaire\n",
        "    corrected_meds = []\n",
        "    for item in extracted_meds:\n",
        "        corrected_name = correct_medicine_name_with_llama(item['drug'], item['dosage'], item['duration'])\n",
        "        corrected_meds.append({\n",
        "            \"drug\": corrected_name,\n",
        "            \"dosage\": item['dosage'],\n",
        "            \"duration\": item['duration']\n",
        "        })\n",
        "\n",
        "    # Afficher les rÃ©sultats\n",
        "    print(\"\\n--- RÃ‰SULTAT FINAL ---\")\n",
        "    print(json.dumps(corrected_meds, indent=2, ensure_ascii=False))\n",
        "else:\n",
        "    print(f\"âš ï¸ Erreur : {extracted_meds.get('error', 'Erreur inconnue')}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import random\n",
        "import httpx\n",
        "from openai import OpenAI\n",
        "\n",
        "# ==============================\n",
        "# ğŸ” CONNEXION API ESPRIT\n",
        "# ==============================\n",
        "ESPRIT_API_KEY = os.getenv(\"ESPRIT_API_KEY\", \"sk-e376096028c847389e18f6d1f650be93\").strip()\n",
        "if not ESPRIT_API_KEY:\n",
        "    raise RuntimeError(\"ESPRIT_API_KEY manquante. DÃ©finis la variable d'environnement ESPRIT_API_KEY.\")\n",
        "\n",
        "http_client = httpx.Client(verify=False, timeout=60.0)\n",
        "client = OpenAI(\n",
        "    api_key=ESPRIT_API_KEY,\n",
        "    base_url=\"https://tokenfactory.esprit.tn/api\",\n",
        "    http_client=http_client\n",
        ")\n",
        "\n",
        "MODEL = \"hosted_vllm/Llama-3.1-70B-Instruct\"\n",
        "\n",
        "# ==============================\n",
        "# ğŸ›¡ï¸ JSON SAFE PARSER\n",
        "# ==============================\n",
        "def safe_json_loads(llm_output: str):\n",
        "    if not llm_output or not llm_output.strip():\n",
        "        raise ValueError(\"RÃ©ponse LLM vide\")\n",
        "\n",
        "    cleaned = llm_output.strip()\n",
        "    cleaned = re.sub(r\"```json\", \"\", cleaned, flags=re.IGNORECASE)\n",
        "    cleaned = re.sub(r\"```\", \"\", cleaned)\n",
        "\n",
        "    match = re.search(r\"\\{.*\\}|\\[.*\\]\", cleaned, re.DOTALL)\n",
        "    if not match:\n",
        "        raise ValueError(f\"Aucun JSON trouvÃ©.\\n---RAW---\\n{cleaned}\\n----------\")\n",
        "\n",
        "    return json.loads(match.group(0))\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# ğŸ§  (A) CLASSIFIEUR LLM : token -> MEDICAMENT/AUTRE\n",
        "# ==============================\n",
        "def classify_token_llm(token: str, ocr_text: str) -> str:\n",
        "    \"\"\"\n",
        "    Retourne STRICTEMENT 'MEDICAMENT' ou 'AUTRE'\n",
        "    (pas de JSON ici, pour Ãªtre ultra robuste).\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "Vous Ãªtes un classifieur strict.\n",
        "\n",
        "TEXTE OCR :\n",
        "{ocr_text}\n",
        "\n",
        "TOKEN :\n",
        "\"{token}\"\n",
        "\n",
        "Question : ce token est-il un NOM DE MEDICAMENT ou un MOT ORDINAIRE ?\n",
        "\n",
        "RÃ©pondez STRICTEMENT par un seul mot :\n",
        "MEDICAMENT\n",
        "ou\n",
        "AUTRE\n",
        "\"\"\"\n",
        "    resp = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"Tu rÃ©ponds strictement au format demandÃ©.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0.0,\n",
        "        max_tokens=5,\n",
        "        top_p=1.0\n",
        "    )\n",
        "    out = (resp.choices[0].message.content or \"\").strip().upper()\n",
        "    if \"MEDICAMENT\" in out:\n",
        "        return \"MEDICAMENT\"\n",
        "    if \"AUTRE\" in out:\n",
        "        return \"AUTRE\"\n",
        "    # fallback : si le modÃ¨le dÃ©rape, on force une normalisation\n",
        "    return \"AUTRE\"\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# ğŸ§© (B) EXPLICATION LLM (dÃ©clarative) en JSON\n",
        "# ==============================\n",
        "def explain_token_llm(token: str, ocr_text: str, base_class: str) -> dict:\n",
        "    \"\"\"\n",
        "    Explication XAI token-spÃ©cifique et comparative.\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "Vous Ãªtes un expert en explicabilitÃ© IA pour le NLP mÃ©dical.\n",
        "\n",
        "Objectif :\n",
        "Expliquer pourquoi le TOKEN analysÃ© joue un rÃ´le de NOM DE MEDICAMENT\n",
        "plutÃ´t qu'un rÃ´le de mot ordinaire DANS CE TEXTE PRÃ‰CIS.\n",
        "\n",
        "IMPORTANT :\n",
        "- L'explication doit Ãªtre centrÃ©e sur le TOKEN, pas sur le texte global.\n",
        "- Comparez explicitement le token Ã  ses mots voisins.\n",
        "- N'expliquez PAS pourquoi le texte est mÃ©dical, mais pourquoi CE token est mÃ©dical.\n",
        "\n",
        "TEXTE OCR :\n",
        "{ocr_text}\n",
        "\n",
        "TOKEN ANALYSÃ‰ :\n",
        "\"{token}\"\n",
        "\n",
        "DÃ‰CISION DU MODÃˆLE :\n",
        "{base_class}\n",
        "\n",
        "FORMAT JSON STRICT :\n",
        "{{\n",
        "  \"classification\": \"{base_class}\",\n",
        "  \"token_role\": \"rÃ´le fonctionnel du token dans la ligne\",\n",
        "  \"local_evidence\": [\n",
        "    \"indice local directement liÃ© au token\",\n",
        "    \"indice local liÃ© Ã  sa position ou relation\"\n",
        "  ],\n",
        "  \"contrast_with_neighbors\": \"pourquoi les mots voisins ne jouent pas le mÃªme rÃ´le\",\n",
        "  \"counterfactual_link\": \"quel Ã©lÃ©ment local, s'il disparaÃ®t, fait changer la dÃ©cision\"\n",
        "}}\n",
        "\"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"RÃ©ponds uniquement en JSON strict.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0.2,\n",
        "        max_tokens=400,\n",
        "        top_p=0.9\n",
        "    )\n",
        "\n",
        "    return safe_json_loads(response.choices[0].message.content or \"\")\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# ğŸ§ª (C) XAI CAUSALE : perturbations automatiques\n",
        "# ==============================\n",
        "def _tokenize_simple(text: str):\n",
        "    # tokenisation simple, sans rÃ¨gles mÃ©tier\n",
        "    # on garde mots / nombres / unitÃ©s collÃ©es comme dans OCR\n",
        "    return re.findall(r\"[A-Za-zÃ€-Ã¿]+|\\d+(?:[.,]\\d+)?|[^\\s]\", text)\n",
        "\n",
        "def _join_tokens(tokens):\n",
        "    # reconstruit un texte \"proche\" de lâ€™original, sans casser trop\n",
        "    return \" \".join(tokens).replace(\" ,\", \",\").replace(\" .\", \".\").replace(\" ;\", \";\").replace(\" :\", \":\")\n",
        "\n",
        "def generate_perturbations(token: str, ocr_text: str, n: int = 18, window: int = 6):\n",
        "    \"\"\"\n",
        "    GÃ©nÃ¨re des variantes du contexte autour du token (masquage/suppression locale),\n",
        "    sans rÃ¨gles mÃ©dicales codÃ©es.\n",
        "    \"\"\"\n",
        "    toks = _tokenize_simple(ocr_text)\n",
        "    # trouver une occurrence (approx) du token\n",
        "    idxs = [i for i, t in enumerate(toks) if t.lower() == token.lower()]\n",
        "    if not idxs:\n",
        "        # si pas trouvÃ©, on renvoie des perturbations globales (masquage alÃ©atoire)\n",
        "        idxs = [len(toks) // 2]\n",
        "    center = idxs[0]\n",
        "\n",
        "    variants = []\n",
        "    for _ in range(n):\n",
        "        vt = toks[:]  # copy\n",
        "        left = max(0, center - window)\n",
        "        right = min(len(vt), center + window + 1)\n",
        "\n",
        "        # on choisit alÃ©atoirement un sous-ensemble Ã  masquer dans la fenÃªtre\n",
        "        candidates = [i for i in range(left, right) if i != center]\n",
        "        k = max(1, int(len(candidates) * random.uniform(0.25, 0.7)))\n",
        "        chosen = random.sample(candidates, k=min(k, len(candidates)))\n",
        "\n",
        "        # deux types de perturbation : MASK ou DROP (alÃ©atoire)\n",
        "        mode = random.choice([\"MASK\", \"DROP\"])\n",
        "        for i in chosen:\n",
        "            if mode == \"MASK\":\n",
        "                vt[i] = \"[MASK]\"\n",
        "            else:\n",
        "                vt[i] = \"\"  # drop\n",
        "\n",
        "        # on garde le token central\n",
        "        vt[center] = toks[center]\n",
        "\n",
        "        # nettoyage des tokens vides\n",
        "        vt_clean = [t for t in vt if t != \"\"]\n",
        "        variants.append(_join_tokens(vt_clean))\n",
        "\n",
        "    # ajouter 2 variantes â€œhardâ€ (sans contexte proche / contexte rÃ©duit)\n",
        "    # (toujours sans rÃ¨gles mÃ©dicales, juste manipulation de fenÃªtre)\n",
        "    only_local = toks[max(0, center - window):min(len(toks), center + window + 1)]\n",
        "    variants.append(_join_tokens(only_local))\n",
        "\n",
        "    without_local = toks[:]\n",
        "    for i in range(max(0, center - window), min(len(toks), center + window + 1)):\n",
        "        if i != center:\n",
        "            without_local[i] = \"[MASK]\"\n",
        "    variants.append(_join_tokens(without_local))\n",
        "\n",
        "    return variants\n",
        "\n",
        "\n",
        "def causal_xai_via_perturbations(token: str, ocr_text: str, n: int = 18, window: int = 6) -> dict:\n",
        "    \"\"\"\n",
        "    XAI forte :\n",
        "    - calcule la stabilitÃ© de la classification sous perturbations\n",
        "    - identifie des perturbations qui font basculer la dÃ©cision (contrefactuels validÃ©s)\n",
        "    \"\"\"\n",
        "    base = classify_token_llm(token, ocr_text)\n",
        "    variants = generate_perturbations(token, ocr_text, n=n, window=window)\n",
        "\n",
        "    results = []\n",
        "    flips = []\n",
        "    for v in variants:\n",
        "        c = classify_token_llm(token, v)\n",
        "        results.append({\"variant_text\": v, \"classification\": c})\n",
        "        if c != base:\n",
        "            flips.append({\"variant_text\": v, \"classification\": c})\n",
        "\n",
        "    stability = 1.0 - (len(flips) / max(1, len(variants)))\n",
        "\n",
        "    # pick a validated counterfactual (first flip)\n",
        "    validated_cf = flips[0] if flips else None\n",
        "\n",
        "    return {\n",
        "        \"base_classification\": base,\n",
        "        \"stability\": round(stability, 3),\n",
        "        \"num_variants\": len(variants),\n",
        "        \"num_flips\": len(flips),\n",
        "        \"validated_counterfactual\": validated_cf,\n",
        "        \"all_variant_results\": results  # tu peux enlever si trop long\n",
        "    }\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# ğŸ’Š Ton extraction (inchangÃ©e) + correction (inchangÃ©e)\n",
        "# ==============================\n",
        "def extract_meds_with_llama(ocr_text):\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "Analysez le texte OCR d'une ordonnance.\n",
        "\n",
        "Extraire tous les mÃ©dicaments SANS corriger.\n",
        "Retournez UNIQUEMENT un JSON strict.\n",
        "\n",
        "FORMAT :\n",
        "[\n",
        "  {{\n",
        "    \"drug\": \"nom extrait\",\n",
        "    \"dosage\": \"posologie brute\",\n",
        "    \"duration\": \"durÃ©e brute\"\n",
        "  }}\n",
        "]\n",
        "\n",
        "TEXTE OCR :\n",
        "{ocr_text}\n",
        "\"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"hosted_vllm/Llama-3.1-70B-Instruct\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"Tu es un assistant mÃ©dical prÃ©cis.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0.3,\n",
        "        max_tokens=700,\n",
        "        top_p=0.9\n",
        "    )\n",
        "\n",
        "    return safe_json_loads(response.choices[0].message.content)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def correct_medicine_name_with_llama(med_name, dosage, duration):\n",
        "    \"\"\"\n",
        "    Appelle llama pour valider ou corriger un nom de mÃ©dicament,\n",
        "    en utilisant le dosage et la durÃ©e comme contexte pour plus de prÃ©cision.\n",
        "    \"\"\"\n",
        "    # Utilisation de f-strings pour inclure les dÃ©tails contextuels\n",
        "    # Utilisation de f-strings pour inclure les dÃ©tails contextuels\n",
        "    prompt = f\"\"\"\n",
        "    Vous Ãªtes un expert en pharmacie, et votre tÃ¢che consiste Ã  valider ou corriger le nom d'un mÃ©dicament, en prenant en compte le contexte donnÃ© par le dosage et la durÃ©e.\n",
        "\n",
        "    Veuillez procÃ©der comme suit :\n",
        "    1. Si le nom extrait semble erronÃ© (par exemple, en raison d'erreurs typographiques ou d'orthographe), suggÃ©rez la correction la plus probable.\n",
        "    2. Si le nom extrait est correct, laissez-le tel quel.\n",
        "    3. Ne vous basez pas sur des rÃ¨gles fixes ou des corrections automatiques. Utilisez uniquement votre expertise pour choisir le nom correct en fonction du contexte.\n",
        "    4. Ne donnez aucune explication supplÃ©mentaire. Limitez-vous au nom du mÃ©dicament corrigÃ© ou confirmÃ©.\n",
        "    \n",
        "    Informations extraites de l'ordonnance :\n",
        "\n",
        "    Nom extrait : {med_name}\n",
        "    Dosage : {dosage}\n",
        "    DurÃ©e : {duration}\n",
        "\n",
        "    Nom final :\n",
        "    \"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"hosted_vllm/Llama-3.1-70B-Instruct\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"Tu es un expert pharmaceutique.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0.3,\n",
        "        max_tokens=50,\n",
        "        top_p=0.9\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# ğŸš€ PIPELINE COMPLET + XAI VALIDÃ‰E\n",
        "# ==============================\n",
        "def full_pipeline_with_validated_xai(ocr_text: str, n_perturb: int = 18, window: int = 6):\n",
        "    extracted = extract_meds_with_llama(ocr_text)\n",
        "\n",
        "    out = []\n",
        "    for item in extracted:\n",
        "        token = item.get(\"drug\", \"\").strip()\n",
        "        dosage = item.get(\"dosage\", \"\")\n",
        "        duration = item.get(\"duration\", \"\")\n",
        "\n",
        "        # 1) XAI causale (stabilitÃ© + contrefactuel validÃ©)\n",
        "        causal = causal_xai_via_perturbations(token, ocr_text, n=n_perturb, window=window)\n",
        "\n",
        "        # 2) Explication dÃ©clarative (mais ancrÃ©e Ã  la dÃ©cision)\n",
        "        expl = explain_token_llm(token, ocr_text, causal[\"base_classification\"])\n",
        "\n",
        "        # 3) Correction (si c'est un mÃ©dicament)\n",
        "        corrected = token\n",
        "        if causal[\"base_classification\"] == \"MEDICAMENT\":\n",
        "            corrected = correct_medicine_name_with_llama(token, dosage, duration)\n",
        "\n",
        "        out.append({\n",
        "            \"original_token\": token,\n",
        "            \"classification\": causal[\"base_classification\"],\n",
        "            \"xai\": {\n",
        "                \"explanation\": expl,\n",
        "                \"causal_validation\": {\n",
        "                    \"stability\": causal[\"stability\"],\n",
        "                    \"num_variants\": causal[\"num_variants\"],\n",
        "                    \"num_flips\": causal[\"num_flips\"],\n",
        "                    \"validated_counterfactual\": causal[\"validated_counterfactual\"]\n",
        "                }\n",
        "            },\n",
        "            \"corrected_drug\": corrected,\n",
        "            \"dosage\": dosage,\n",
        "            \"duration\": duration\n",
        "        })\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# ğŸ§ª RUN\n",
        "# ==============================\n",
        "if __name__ == \"__main__\":\n",
        "    random.seed(42)\n",
        "\n",
        "    ocr_text_input = (\n",
        "        \"Rx Tab Auguentin 625mg x5day \"\n",
        "        \"Enzoflarn 5days \"\n",
        "        \"PaniD 40mg before meals \"\n",
        "        \"Hexigel gum paste 1week\"\n",
        "    )\n",
        "\n",
        "    result = full_pipeline_with_validated_xai(ocr_text_input, n_perturb=14, window=5)\n",
        "    print(json.dumps(result, indent=2, ensure_ascii=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Comment fonctionne ton XAI (en 4 Ã©tapes simples)\n",
        "ğŸ”¹ Ã‰tape 1 â€” DÃ©cision de base\n",
        "\n",
        "Le LLM dÃ©cide :\n",
        "\n",
        "MEDICAMENT ou AUTRE\n",
        "pour chaque token extrait de lâ€™OCR.\n",
        "\n",
        "ğŸ”¹ Ã‰tape 2 â€” Explication locale (XAI dÃ©clarative)\n",
        "\n",
        "Le modÃ¨le explique :\n",
        "\n",
        "le rÃ´le du token\n",
        "\n",
        "les indices locaux (dosage, position, voisins)\n",
        "\n",
        "pourquoi les mots autour ne sont pas des mÃ©dicaments\n",
        "\n",
        "ce qui ferait changer la dÃ©cision (contre-exemple)\n",
        "\n",
        "-> Câ€™est une explication humaine, lisible\n",
        "\n",
        "ğŸ”¹ Ã‰tape 3 â€” Validation causale (XAI forte)\n",
        "\n",
        "On modifie automatiquement le texte autour du token :\n",
        "\n",
        "masquage\n",
        "\n",
        "suppression locale\n",
        "\n",
        "rÃ©duction du contexte\n",
        "\n",
        "Puis on regarde :\n",
        "\n",
        "si la dÃ©cision reste stable\n",
        "\n",
        "ou si elle bascule\n",
        "\n",
        "-> Si la dÃ©cision change, on a un contrefactuel validÃ©\n",
        "\n",
        "ğŸ”¹ Ã‰tape 4 â€” Score de confiance implicite\n",
        "\n",
        "Ã€ partir des perturbations, on calcule :\n",
        "\n",
        "stability score (robustesse)\n",
        "\n",
        "nombre de changements de dÃ©cision\n",
        "\n",
        "-> Plus câ€™est stable, plus la dÃ©cision est fiable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install sentence-transformers\n",
        "!pip install faiss-cpu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip uninstall -y sentence-transformers huggingface-hub transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip list | findstr transformer\n",
        "!pip list | findstr hugging\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install huggingface-hub==0.19.4\n",
        "!pip install transformers==4.36.2\n",
        "!pip install sentence-transformers==2.3.1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "print(\"OK !\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "\n",
        "# ALWAYS CPU\n",
        "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\", device=\"cpu\")\n",
        "\n",
        "def compute_embeddings(text_list):\n",
        "    embeddings = embedder.encode(text_list, convert_to_numpy=True, normalize_embeddings=True)\n",
        "    return embeddings.astype(\"float32\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import faiss\n",
        "\n",
        "def create_faiss_index(embeddings):\n",
        "    dim = embeddings.shape[1]\n",
        "    index = faiss.IndexFlatIP(dim)  # cos similarity\n",
        "    index.add(embeddings)\n",
        "    return index\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def match_drug_embeddings(drug_name, df, index, embeddings, threshold=0.60):\n",
        "\n",
        "    query_emb = compute_embeddings([drug_name])  # (1, 384)\n",
        "\n",
        "    scores, indices = index.search(query_emb, k=1)\n",
        "    score = scores[0][0]\n",
        "    idx = indices[0][0]\n",
        "\n",
        "    if score >= threshold:\n",
        "        return df[\"canonical\"].iloc[idx], score\n",
        "\n",
        "    return None, score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(r\"C:\\Users\\hp\\Desktop\\4Ã¨me\\projet\\medicaments_clean_for_ocr.csv\")\n",
        "\n",
        "# Compute dataset embeddings\n",
        "dataset_embeddings = compute_embeddings(df[\"canonical\"].tolist())\n",
        "\n",
        "# Build index\n",
        "index = create_faiss_index(dataset_embeddings)\n",
        "\n",
        "# Query\n",
        "drug = \"ENZOFLan\"\n",
        "match, score = match_drug_embeddings(drug, df, index, dataset_embeddings)\n",
        "\n",
        "print(match, score)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "def add_drug_to_dataset(drug_name, medical_card, df, dataset_path):\n",
        "    # Convert JSON â†’ string\n",
        "    med_card_str = json.dumps(medical_card, ensure_ascii=False)\n",
        "\n",
        "    new_row = {\n",
        "        \"canonical\": drug_name,\n",
        "        \"med_card\": med_card_str\n",
        "    }\n",
        "\n",
        "    df = df.append(new_row, ignore_index=True)\n",
        "\n",
        "    # Save to disk\n",
        "    df.to_csv(dataset_path, index=False, encoding=\"utf-8\")\n",
        "\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Charger dataset\n",
        "dataset_path = r\"C:\\Users\\hp\\Desktop\\4Ã¨me\\projet\\medicaments_clean_for_ocr.csv\"\n",
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "# VÃ©rifier si la colonne existe sinon la crÃ©er\n",
        "if \"med_card\" not in df.columns:\n",
        "    df[\"med_card\"] = \"\"  # colonne vide\n",
        "    df.to_csv(dataset_path, index=False, encoding=\"utf-8\")\n",
        "    print(\"ğŸ†• Colonne 'med_card' ajoutÃ©e au dataset.\")\n",
        "else:\n",
        "    print(\"âœ” Colonne 'med_card' dÃ©jÃ  existante.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_drug(med, df, index, embeddings, dataset_path):\n",
        "\n",
        "    # 1ï¸âƒ£ Correction LLM\n",
        "    corrected_name = correct_medicine_name_with_llama(\n",
        "        med[\"drug\"], med[\"dosage\"], med[\"duration\"]\n",
        "    )\n",
        "    print(f\"\\nğŸ”§ Nom corrigÃ© : {corrected_name}\")\n",
        "\n",
        "    # 2ï¸âƒ£ Matching embedding sur NOM CORRIGÃ‰\n",
        "    match, score = match_drug_embeddings(corrected_name, df, index, embeddings)\n",
        "\n",
        "    # 3ï¸âƒ£ Si mÃ©dicament connu\n",
        "    if match:\n",
        "        print(f\"âœ” Match trouvÃ© : {corrected_name} â†’ {match} (score={score:.2f})\")\n",
        "\n",
        "        row = df[df[\"canonical\"] == match].iloc[0]\n",
        "        raw_card = row[\"med_card\"]\n",
        "\n",
        "        # ---- CAS : Carte dÃ©jÃ  existante ----\n",
        "        if isinstance(raw_card, str) and raw_card.strip() not in [\"\", \"nan\", \"None\"]:\n",
        "            print(f\"ğŸ“„ Carte mÃ©dicale trouvÃ©e pour {match}.\")\n",
        "            med_card = json.loads(raw_card)\n",
        "            return match, med_card, df, index, embeddings\n",
        "\n",
        "        # ---- CAS : Carte manquante â†’ gÃ©nÃ©rer nouvelle carte ----\n",
        "        print(f\"âš ï¸ Carte mÃ©dicale absente dans dataset pour {match}. GÃ©nÃ©ration en coursâ€¦\")\n",
        "        med_card = generate_medical_card(match)\n",
        "\n",
        "        # Mise Ã  jour dataset\n",
        "        df.loc[df[\"canonical\"] == match, \"med_card\"] = json.dumps(med_card, ensure_ascii=False)\n",
        "        df.to_csv(dataset_path, index=False, encoding=\"utf-8\")\n",
        "\n",
        "        return match, med_card, df, index, embeddings\n",
        "\n",
        "    # 4ï¸âƒ£ Aucun match â†’ nouveau mÃ©dicament\n",
        "    print(f\"âŒ Aucun match pour {corrected_name} â†’ gÃ©nÃ©ration carte mÃ©dicaleâ€¦\")\n",
        "    med_card = generate_medical_card(corrected_name)\n",
        "\n",
        "    # Ajout dans dataset\n",
        "    new_row = {\n",
        "        \"canonical\": corrected_name,\n",
        "        \"med_card\": json.dumps(med_card, ensure_ascii=False)\n",
        "    }\n",
        "    \n",
        "    df = df.append(new_row, ignore_index=True)\n",
        "    df.to_csv(dataset_path, index=False, encoding=\"utf-8\")\n",
        "\n",
        "    print(f\"ğŸ†• MÃ©dicament ajoutÃ© au dataset : {corrected_name}\")\n",
        "\n",
        "    # Rebuild embeddings & FAISS\n",
        "    embeddings = compute_embeddings(df[\"canonical\"].tolist())\n",
        "    index = create_faiss_index(embeddings)\n",
        "\n",
        "    return corrected_name, med_card, df, index, embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#######################################\n",
        "# ğŸ”¥ TEST COMPLET DU PIPELINE ğŸ”¥\n",
        "#######################################\n",
        "\n",
        "# Emplacement rÃ©el de ton dataset\n",
        "dataset_path = \"C:/Users/hp/Desktop/4Ã¨me/projet/medicaments_clean_for_ocr.csv\"\n",
        "\n",
        "print(\"ğŸ“Œ Chargement du dataset...\")\n",
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "# Ajouter colonne med_card si elle n'existe pas\n",
        "if \"med_card\" not in df.columns:\n",
        "    df[\"med_card\"] = \"\"\n",
        "    df.to_csv(dataset_path, index=False, encoding=\"utf-8\")\n",
        "    print(\"ğŸ†• Colonne 'med_card' ajoutÃ©e.\")\n",
        "\n",
        "print(\"ğŸ“Œ Calcul des embeddings...\")\n",
        "embeddings = compute_embeddings(df[\"canonical\"].tolist())\n",
        "\n",
        "print(\"ğŸ“Œ CrÃ©ation de l'index FAISS...\")\n",
        "index = create_faiss_index(embeddings)\n",
        "\n",
        "\n",
        "########################################\n",
        "# ğŸ” TEST OCR INPUT\n",
        "########################################\n",
        "\n",
        "ocr_text = \"\"\"\n",
        "Tab ENZOFLan 5mg x5day\n",
        "PaniD 40mg before meals\n",
        "Augmentin 1g x3day\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\nğŸ§ª OCR fourni :\")\n",
        "print(ocr_text)\n",
        "\n",
        "\n",
        "########################################\n",
        "# ğŸ§ª EXTRACTION BRUTE\n",
        "########################################\n",
        "\n",
        "extracted = extract_and_correct_meds_with_llama(ocr_text)\n",
        "\n",
        "print(\"\\nğŸ” MÃ©dicaments extraits (brut OCR) :\")\n",
        "print(json.dumps(extracted, indent=2, ensure_ascii=False))\n",
        "\n",
        "\n",
        "########################################\n",
        "# ğŸ”¥ TRAITEMENT DE CHAQUE MÃ‰DICAMENT\n",
        "########################################\n",
        "\n",
        "final_output = []\n",
        "\n",
        "for med in extracted:\n",
        "    drug_name, med_card, df, index, embeddings = process_drug(\n",
        "        med, df, index, embeddings, dataset_path\n",
        "    )\n",
        "\n",
        "    final_output.append({\n",
        "        \"drug\": drug_name,\n",
        "        \"dosage\": med[\"dosage\"],\n",
        "        \"duration\": med[\"duration\"],\n",
        "        \"card\": med_card\n",
        "    })\n",
        "\n",
        "\n",
        "########################################\n",
        "# ğŸ‰ RESULTAT FINAL\n",
        "########################################\n",
        "\n",
        "print(\"\\n\\nğŸ‰=== RÃ‰SULTAT FINAL DU PIPELINE ===ğŸ‰\")\n",
        "print(json.dumps(final_output, indent=2, ensure_ascii=False))\n",
        "\n",
        "print(\"\\nğŸ“Œ VÃ©rification : dataset mis Ã  jour â†’ OK\")\n",
        "print(\"ğŸ“Œ Embeddings recalculÃ©s â†’ OK\")\n",
        "print(\"ğŸ“Œ Index FAISS reconstruit â†’ OK\")\n",
        "\n",
        "print(\"\\nğŸ¯ TEST TERMINÃ‰ â€” TON PIPELINE FONCTIONNE âœ”\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_medical_context(drug_list, df):\n",
        "    context_parts = []\n",
        "\n",
        "    for drug in drug_list:\n",
        "        # ğŸ”¹ match insensible Ã  la casse\n",
        "        mask = df[\"canonical\"].astype(str).str.lower() == drug.lower()\n",
        "        rows = df[mask]\n",
        "\n",
        "        if rows.empty:\n",
        "            print(f\"âš ï¸ Aucun mÃ©doc trouvÃ© dans le dataset pour : {drug}\")\n",
        "            continue\n",
        "\n",
        "        row = rows.iloc[0]\n",
        "        raw_card = row.get(\"med_card\", \"\")\n",
        "\n",
        "        # si pas de carte â†’ on peut soit sauter, soit mettre un placeholder\n",
        "        if pd.isna(raw_card) or raw_card in [\"\", \"nan\", None]:\n",
        "            print(f\"âš ï¸ med_card vide pour : {drug}\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            card = json.loads(raw_card)\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ Erreur JSON pour med_card de {drug} : {e}\")\n",
        "            continue\n",
        "\n",
        "        context_parts.append(json.dumps(card, ensure_ascii=False, indent=2))\n",
        "\n",
        "    return \"\\n\\n\".join(context_parts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_rag_prompt(question, context):\n",
        "    return f\"\"\"\n",
        "Tu es un expert mÃ©dical spÃ©cialisÃ© dans les interactions mÃ©dicamenteuses.\n",
        "\n",
        "Contexte clinique provenant des cartes mÃ©dicales extraites du dataset :\n",
        "\n",
        "{context}\n",
        "\n",
        "RÃ¨gles :\n",
        "- Utilise PRIORITAIREMENT ce contexte pour rÃ©pondre.\n",
        "- Tu peux complÃ©ter avec tes connaissances mÃ©dicales internes si nÃ©cessaire.\n",
        "- RÃ©pond toujours de maniÃ¨re claire, simple et exacte.\n",
        "- Mentionne explicitement les interactions possibles.\n",
        "- Donne Ã©ventuellement des recommandations pratiques.\n",
        "\n",
        "Question :\n",
        "{question}\n",
        "\n",
        "RÃ©ponse :\n",
        "\"\"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ask_medical_question(question, drug_list, df):\n",
        "    context = get_medical_context(drug_list, df)\n",
        "    prompt = build_rag_prompt(question, context)\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"hosted_vllm/Llama-3.1-70B-Instruct\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"Assistant mÃ©dical fiable et prudent.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0.2,\n",
        "        max_tokens=500\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content.strip()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ask_about_prescription(question, final_output, df):\n",
        "    # Liste des mÃ©dicaments reconnus aprÃ¨s correction + matching\n",
        "    drugs = [item[\"drug\"] for item in final_output]\n",
        "\n",
        "    print(\"\\nğŸ“Œ MÃ©dicaments concernÃ©s par la question :\", drugs)\n",
        "\n",
        "    answer = ask_medical_question(question, drugs, df)\n",
        "\n",
        "    return answer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "question = \"Est-ce que je peux prendre Augmentin avec Pantoprazole ?\"\n",
        "\n",
        "print(\"\\nğŸ§  QUESTION :\", question)\n",
        "\n",
        "answer = ask_about_prescription(question, final_output, df)\n",
        "\n",
        "print(\"\\nğŸ’¬ RÃ‰PONSE RAG :\\n\")\n",
        "print(answer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "conversation_history = []  # mÃ©moire du chat\n",
        "\n",
        "\n",
        "def ask_medical_question_conversational(question, drug_list, df):\n",
        "    # 1. Construire contexte mÃ©dical\n",
        "    context = get_medical_context(drug_list, df)\n",
        "\n",
        "    # 2. Construire le message utilisateur pour ce tour\n",
        "    user_message = f\"\"\"\n",
        "Contexte des mÃ©dicaments :\n",
        "{context}\n",
        "\n",
        "Question de l'utilisateur :\n",
        "{question}\n",
        "\"\"\"\n",
        "\n",
        "    # 3. Construire la conversation complÃ¨te\n",
        "    messages = [{\"role\": \"system\", \"content\": \"Assistant mÃ©dical expert, prudent, clair et fiable.\"}]\n",
        "\n",
        "    # Ajouter historique\n",
        "    for entry in conversation_history:\n",
        "        messages.append({\"role\": entry[\"role\"], \"content\": entry[\"content\"]})\n",
        "\n",
        "    # Ajouter le nouveau message\n",
        "    messages.append({\"role\": \"user\", \"content\": user_message})\n",
        "\n",
        "    # 4. Appeler le modÃ¨le\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"hosted_vllm/Llama-3.1-70B-Instruct\",\n",
        "        messages=messages,\n",
        "        temperature=0.25,\n",
        "        max_tokens=500\n",
        "    )\n",
        "\n",
        "    answer = response.choices[0].message.content.strip()\n",
        "\n",
        "    # 5. Ajouter ce tour dans l'historique\n",
        "    conversation_history.append({\"role\": \"user\", \"content\": question})\n",
        "    conversation_history.append({\"role\": \"assistant\", \"content\": answer})\n",
        "\n",
        "    return answer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def chat_with_prescription(question, final_output, df):\n",
        "    drugs = [item[\"drug\"] for item in final_output]\n",
        "    answer = ask_medical_question_conversational(question, drugs, df)\n",
        "    return answer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"ğŸ’¬ Assistant MÃ©dical Intelligent â€” Mode Conversation\")\n",
        "print(\"Tape 'exit' pour quitter.\\n\")\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"ğŸ‘¤ Vous : \")\n",
        "\n",
        "    if user_input.lower().strip() in [\"exit\", \"quit\"]:\n",
        "        print(\"ğŸ‘‹ Fin de la conversation.\")\n",
        "        break\n",
        "\n",
        "    answer = chat_with_prescription(user_input, final_output, df)\n",
        "\n",
        "    print(\"\\nğŸ§  QUESTION :\")\n",
        "    print(user_input)\n",
        "\n",
        "    print(\"\\nğŸ¤– RÃ‰PONSE :\")\n",
        "    print(answer)\n",
        "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "import json\n",
        "\n",
        "def extract_json_block(text):\n",
        "    \"\"\"\n",
        "    Extrait proprement un bloc JSON depuis une rÃ©ponse LLM contenant du texte avant/aprÃ¨s.\n",
        "    \"\"\"\n",
        "    match = re.search(r\"\\{[\\s\\S]*\\}\", text)\n",
        "    if match:\n",
        "        json_text = match.group(0)\n",
        "        try:\n",
        "            return json.loads(json_text)\n",
        "        except Exception as e:\n",
        "            print(\"âš ï¸ JSON dÃ©tectÃ© mais impossible Ã  parser :\", e)\n",
        "            return None\n",
        "    return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def self_check_llm(context, question, answer):\n",
        "    \"\"\"\n",
        "    VÃ©rifie la rÃ©ponse gÃ©nÃ©rÃ©e par le RAG :\n",
        "      - erreurs mÃ©dicales ?\n",
        "      - interaction inventÃ©e ?\n",
        "      - hallucination ?\n",
        "      - rÃ©ponse corrigÃ©e ?\n",
        "    Retourne un texte LLM contenant du JSON.\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "Tu es un examinateur mÃ©dical strict et objectif.\n",
        "\n",
        "Analyse la rÃ©ponse suivante et dÃ©tecte :\n",
        "\n",
        "1. Si une interaction mÃ©dicamenteuse a Ã©tÃ© INVENTÃ‰E.\n",
        "2. Si la rÃ©ponse contient une ERREUR MÃ‰DICALE.\n",
        "3. Si la rÃ©ponse contient une HALLUCINATION.\n",
        "4. Si la rÃ©ponse peut prÃ©senter un RISQUE pour lâ€™utilisateur.\n",
        "5. Donne un score de certitude (0â€“100).\n",
        "6. Si incorrect â†’ propose une version corrigÃ©e.\n",
        "\n",
        "RÃ©pond STRICTEMENT en JSON selon le modÃ¨le :\n",
        "\n",
        "{{\n",
        "  \"invented_interaction\": true/false,\n",
        "  \"medical_error\": true/false,\n",
        "  \"hallucination\": true/false,\n",
        "  \"risk\": true/false,\n",
        "  \"certainty\": \"xx/100\",\n",
        "  \"corrected_answer\": \"...\"\n",
        "}}\n",
        "\n",
        "CONTEXT :\n",
        "{context}\n",
        "\n",
        "QUESTION :\n",
        "{question}\n",
        "\n",
        "ANSWER :\n",
        "{answer}\n",
        "\"\"\"\n",
        "\n",
        "    resp = client.chat.completions.create(\n",
        "        model=\"hosted_vllm/Llama-3.1-70B-Instruct\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.3,\n",
        "        max_tokens=500\n",
        "    )\n",
        "\n",
        "    return resp.choices[0].message.content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ask_with_xai(question, final_output, df):\n",
        "    \"\"\"\n",
        "    1. Construit le contexte RAG\n",
        "    2. GÃ©nÃ¨re une rÃ©ponse (RAG)\n",
        "    3. VÃ©rifie la rÃ©ponse via XAI (self-check)\n",
        "    4. Applique un safety-layer si risque dÃ©tectÃ©\n",
        "    \"\"\"\n",
        "\n",
        "    # 1) mÃ©dicaments concernÃ©s\n",
        "    drugs = [item[\"drug\"] for item in final_output]\n",
        "\n",
        "    # 2) Contexte RAG\n",
        "    context = \"\"\n",
        "    context_cards = {}\n",
        "    for drug in drugs:\n",
        "        card = get_medical_context([drug], df)\n",
        "        context_cards[drug] = card\n",
        "        context += f\"\\n\\n[{drug.upper()}]\\n{card}\"\n",
        "\n",
        "    # 3) rÃ©ponse brute\n",
        "    raw_answer = ask_medical_question_conversational(question, drugs, df)\n",
        "\n",
        "    # 4) attribution\n",
        "    retrieval = explain_retrieval(question, context_cards)\n",
        "\n",
        "    # 5) Self-check\n",
        "    report_raw = self_check_llm(context, question, raw_answer)\n",
        "    quality = extract_json_block(report_raw)\n",
        "\n",
        "    # -------------------------------\n",
        "    # ğŸŒ™ 6) SÃ©lection de la rÃ©ponse finale\n",
        "    # -------------------------------\n",
        "\n",
        "    safety_note = \"\"\n",
        "    final_answer = raw_answer  # valeur par dÃ©faut\n",
        "\n",
        "    if quality is None:\n",
        "        final_answer = raw_answer\n",
        "        safety_note = \"âš ï¸ Le self-check nâ€™a pas pu Ãªtre analysÃ©.\"\n",
        "    \n",
        "    else:\n",
        "        invented = quality.get(\"invented_interaction\", False)\n",
        "        med_error = quality.get(\"medical_error\", False)\n",
        "        risk = quality.get(\"risk\", False)\n",
        "        corrected = quality.get(\"corrected_answer\", \"\").strip()\n",
        "\n",
        "        # 6A â€“ utiliser la rÃ©ponse corrigÃ©e si erreur dÃ©tectÃ©e\n",
        "        if invented or med_error:\n",
        "            final_answer = corrected if corrected else raw_answer\n",
        "            safety_note = \"âš ï¸ RÃ©ponse initiale corrigÃ©e (erreur dÃ©tectÃ©e par XAI).\"\n",
        "\n",
        "        # 6B â€“ ğŸŒ‹ SAFETY-LAYER : risques dÃ©tectÃ©s  \n",
        "        if risk:\n",
        "            final_answer = (\n",
        "                \"âš ï¸ Cette question concerne une interaction mÃ©dicale potentiellement risquÃ©e. \"\n",
        "                \"Je ne peux pas fournir de rÃ©ponse dÃ©finitive. \"\n",
        "                \"Veuillez demander l'avis dâ€™un mÃ©decin ou dâ€™un pharmacien.\"\n",
        "            )\n",
        "            safety_note = \"ğŸ›‘ RÃ©ponse bloquÃ©e (risque dÃ©tectÃ© par le modÃ¨le).\"\n",
        "\n",
        "        # 6C â€“ rÃ©ponse validÃ©e\n",
        "        if not invented and not med_error and not risk:\n",
        "            safety_note = \"âœ” RÃ©ponse validÃ©e par le self-check.\"\n",
        "\n",
        "    return {\n",
        "        \"question\": question,\n",
        "        \"answer_raw\": raw_answer,\n",
        "        \"answer_final\": final_answer,\n",
        "        \"quality_report\": quality,\n",
        "        \"retrieval\": retrieval,\n",
        "        \"safety_note\": safety_note\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_system(questions, final_output, df):\n",
        "    \"\"\"\n",
        "    ExÃ©cute N questions et retourne un DataFrame avec :\n",
        "    - rÃ©ponse brute\n",
        "    - rÃ©ponse finale\n",
        "    - erreurs dÃ©tectÃ©es\n",
        "    - mÃ©triques XAI\n",
        "    \"\"\"\n",
        "\n",
        "    logs = []\n",
        "\n",
        "    for q in questions:\n",
        "        print(f\"\\nğŸ” QUESTION : {q}\")\n",
        "        result = ask_with_xai(q, final_output, df)\n",
        "\n",
        "        report = result[\"quality_report\"]\n",
        "        invented = med_error = halluc = risk = None\n",
        "        certainty = None\n",
        "\n",
        "        if report:\n",
        "            invented = report[\"invented_interaction\"]\n",
        "            med_error = report[\"medical_error\"]\n",
        "            halluc = report[\"hallucination\"]\n",
        "            risk = report[\"risk\"]\n",
        "            certainty = report[\"certainty\"]\n",
        "\n",
        "        logs.append({\n",
        "            \"question\": q,\n",
        "            \"raw_answer\": result[\"answer_raw\"],\n",
        "            \"final_answer\": result[\"answer_final\"],\n",
        "            \"invented_interaction\": invented,\n",
        "            \"medical_error\": med_error,\n",
        "            \"hallucination\": halluc,\n",
        "            \"risk\": risk,\n",
        "            \"certainty\": certainty,\n",
        "            \"safety_note\": result[\"safety_note\"]\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(logs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "questions_test = [\n",
        "    \"Que faire si jâ€™ai oubliÃ© une dose dâ€™Augmentin ?\",\n",
        "    \"Puis-je prendre deux Pantoprazole si jâ€™ai oubliÃ© la dose dâ€™hier ?\",\n",
        "    \"Combien de jours faut-il pour que lâ€™Augmentin fasse effet ?\",\n",
        "]\n",
        "\n",
        "df_eval = evaluate_system(questions_test, final_output, df)\n",
        "\n",
        "df_eval\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_global_metrics(df_eval):\n",
        "    \"\"\"\n",
        "    df_eval doit contenir les colonnes :\n",
        "    - invented_interaction\n",
        "    - medical_error\n",
        "    - hallucination\n",
        "    - risk\n",
        "    - certainty (xx/100)\n",
        "    \"\"\"\n",
        "\n",
        "    n = len(df_eval)\n",
        "\n",
        "    def pct(col):\n",
        "        return round(df_eval[col].fillna(False).mean() * 100, 2)\n",
        "\n",
        "    taux_interaction = pct(\"invented_interaction\")\n",
        "    taux_erreur = pct(\"medical_error\")\n",
        "    taux_hallu = pct(\"hallucination\")\n",
        "    taux_risk = pct(\"risk\")\n",
        "\n",
        "    # Certitude moyenne\n",
        "    certitudes = []\n",
        "    for c in df_eval[\"certainty\"]:\n",
        "        try:\n",
        "            certitudes.append(float(c.replace(\"/100\", \"\")))\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    certitude_moy = round(sum(certitudes) / len(certitudes), 2) if certitudes else None\n",
        "\n",
        "    # SCORE GLOBAL DE SÃ‰CURITÃ‰ (0 = dangereux, 100 = excellent)\n",
        "    score_securite = max(0, 100 - (taux_interaction * 1.5 + taux_erreur * 2 + taux_hallu * 1.2 + taux_risk * 0.5))\n",
        "    score_securite = round(score_securite, 2)\n",
        "\n",
        "    metrics = {\n",
        "        \"Nombre de questions\": n,\n",
        "        \"Taux interactions inventÃ©es (%)\": taux_interaction,\n",
        "        \"Taux erreurs mÃ©dicales (%)\": taux_erreur,\n",
        "        \"Taux hallucinations (%)\": taux_hallu,\n",
        "        \"Taux rÃ©ponses Ã  risque (%)\": taux_risk,\n",
        "        \"Certitude moyenne (%)\": certitude_moy,\n",
        "        \"Score global de sÃ©curitÃ© /100\": score_securite\n",
        "    }\n",
        "\n",
        "    return metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metrics = compute_global_metrics(df_eval)\n",
        "\n",
        "print(\"\\nğŸ“Š MÃ‰TRIQUES GLOBALES DU SYSTÃˆME\\n\")\n",
        "for k, v in metrics.items():\n",
        "    print(f\"- {k}: {v}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def rule_based_medical_logic(question):\n",
        "    q = question.lower()\n",
        "\n",
        "    # 1ï¸âƒ£ OUBLI DE DOSE\n",
        "    if \"oubli\" in q or \"oubliÃ©\" in q:\n",
        "        return (\n",
        "            \"Si vous avez oubliÃ© une dose, prenez-la dÃ¨s que possible sauf sâ€™il est \"\n",
        "            \"presque lâ€™heure de la suivante. Ne doublez jamais la dose.\"\n",
        "        )\n",
        "\n",
        "    # 2ï¸âƒ£ DOUBLE DOSE\n",
        "    if (\"deux\" in q or \"double\" in q) and \"dose\" in q:\n",
        "        return (\n",
        "            \"Il nâ€™est pas recommandÃ© de doubler une dose. Attendez la prochaine prise prÃ©vue.\"\n",
        "        )\n",
        "\n",
        "    # 3ï¸âƒ£ DÃ‰LAI D'EFFET\n",
        "    if \"combien de jours\" in q or \"agit\" in q or \"effet\" in q:\n",
        "        return (\n",
        "            \"Lâ€™Augmentin et la plupart des antibiotiques commencent Ã  agir en 24 Ã  48 heures. \"\n",
        "            \"Si les symptÃ´mes persistent ou s'aggravent, consultez un mÃ©decin.\"\n",
        "        )\n",
        "\n",
        "    # 4ï¸âƒ£ ALCOOL\n",
        "    if \"alcool\" in q:\n",
        "        return (\n",
        "            \"Ã‰vitez lâ€™alcool pendant un traitement, car il peut augmenter les effets secondaires \"\n",
        "            \"digestifs ou altÃ©rer la tolÃ©rance du mÃ©dicament.\"\n",
        "        )\n",
        "\n",
        "    # 5ï¸âƒ£ REPAS\n",
        "    if \"repas\" in q or \"manger\" in q:\n",
        "        return (\n",
        "            \"Certains mÃ©dicaments doivent Ãªtre pris Ã  jeun (comme le Pantoprazole), \"\n",
        "            \"et dâ€™autres avec un repas (comme lâ€™Augmentin).\"\n",
        "        )\n",
        "\n",
        "    return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ask_with_xai(question, final_output, df):\n",
        "    \"\"\"\n",
        "    Pipeline complet :\n",
        "    1. Rule-based\n",
        "    2. RAG\n",
        "    3. Self-check\n",
        "    4. Safety-layer\n",
        "    \"\"\"\n",
        "\n",
        "    # -----------------------------\n",
        "    # 0ï¸âƒ£ RULE-BASED (anti-hallucination)\n",
        "    # -----------------------------\n",
        "    rule_answer = rule_based_medical_logic(question)\n",
        "    if rule_answer is not None:\n",
        "        return {\n",
        "            \"question\": question,\n",
        "            \"answer_raw\": rule_answer,\n",
        "            \"answer_final\": rule_answer,\n",
        "            \"quality_report\": None,\n",
        "            \"retrieval\": [],\n",
        "            \"safety_note\": \"âœ” RÃ©ponse sÃ©curisÃ©e via module rule-based (pas de LLM utilisÃ©).\"\n",
        "        }\n",
        "\n",
        "    # -----------------------------\n",
        "    # 1ï¸âƒ£ Construire le contexte RAG\n",
        "    # -----------------------------\n",
        "    drugs = [item[\"drug\"] for item in final_output]\n",
        "    context = \"\"\n",
        "    context_cards = {}\n",
        "\n",
        "    for drug in drugs:\n",
        "        card_text = get_medical_context([drug], df)\n",
        "        context_cards[drug] = card_text\n",
        "        context += f\"\\n[{drug.upper()}]\\n{card_text}\\n\"\n",
        "\n",
        "    # -----------------------------\n",
        "    # 2ï¸âƒ£ RÃ©ponse brute via RAG LLM\n",
        "    # -----------------------------\n",
        "    raw_answer = ask_medical_question_conversational(question, drugs, df)\n",
        "\n",
        "    # FILTRE : si le modÃ¨le dit \"info absente du contexte\"\n",
        "    if \"absente du contexte\" in raw_answer.lower():\n",
        "        return {\n",
        "            \"question\": question,\n",
        "            \"answer_raw\": raw_answer,\n",
        "            \"answer_final\": raw_answer,\n",
        "            \"quality_report\": None,\n",
        "            \"retrieval\": [],\n",
        "            \"safety_note\": \"â„¹ï¸ Lâ€™information nâ€™est pas prÃ©sente dans le contexte RAG.\"\n",
        "        }\n",
        "\n",
        "    # RÃ©cupÃ©ration pour attribution\n",
        "    retrieval = explain_retrieval(question, context_cards)\n",
        "\n",
        "    # -----------------------------\n",
        "    # 3ï¸âƒ£ SELF-CHECK LLM\n",
        "    # -----------------------------\n",
        "    report_raw = self_check_llm(context, question, raw_answer)\n",
        "    quality = extract_json_block(report_raw)\n",
        "\n",
        "    final_answer = raw_answer\n",
        "    safety_note = \"\"\n",
        "\n",
        "    # Aucune analyse possible â†’ montrer RAG brut (rare)\n",
        "    if quality is None:\n",
        "        return {\n",
        "            \"question\": question,\n",
        "            \"answer_raw\": raw_answer,\n",
        "            \"answer_final\": raw_answer,\n",
        "            \"quality_report\": None,\n",
        "            \"retrieval\": retrieval,\n",
        "            \"safety_note\": \"âš ï¸ Self-check illisible. RÃ©ponse brute affichÃ©e.\"\n",
        "        }\n",
        "\n",
        "    invented = quality.get(\"invented_interaction\", False)\n",
        "    med_error = quality.get(\"medical_error\", False)\n",
        "    risk = quality.get(\"risk\", False)\n",
        "    corrected = quality.get(\"corrected_answer\", \"\").strip()\n",
        "\n",
        "    # -----------------------------\n",
        "    # 4ï¸âƒ£ Correction automatique\n",
        "    # -----------------------------\n",
        "    if invented or med_error:\n",
        "        final_answer = corrected if corrected else raw_answer\n",
        "        safety_note = \"âš ï¸ RÃ©ponse corrigÃ©e (erreur dÃ©tectÃ©e par self-check).\"\n",
        "\n",
        "    # -----------------------------\n",
        "    # 5ï¸âƒ£ SAFETY-LAYER (niveau mÃ©dical)\n",
        "    # -----------------------------\n",
        "    if risk:\n",
        "        final_answer = (\n",
        "            \"âš ï¸ Cette question implique un risque mÃ©dical potentiel. \"\n",
        "            \"Je ne peux pas fournir de rÃ©ponse dÃ©finitive. \"\n",
        "            \"Veuillez consulter un mÃ©decin ou un pharmacien.\"\n",
        "        )\n",
        "        safety_note = \"ğŸ›‘ RÃ©ponse bloquÃ©e (risque dÃ©tectÃ© par le self-check).\"\n",
        "\n",
        "    # -----------------------------\n",
        "    # ğŸ”š 6ï¸âƒ£ Retour final\n",
        "    # -----------------------------\n",
        "    return {\n",
        "        \"question\": question,\n",
        "        \"answer_raw\": raw_answer,\n",
        "        \"answer_final\": final_answer,\n",
        "        \"quality_report\": quality,\n",
        "        \"retrieval\": retrieval,\n",
        "        \"safety_note\": safety_note\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "##############################################\n",
        "# ğŸ”¥ TESTS COMPLETS DU SYSTÃˆME RAG + RULE + XAI\n",
        "##############################################\n",
        "\n",
        "test_questions = [\n",
        "    \"Que faire si jâ€™ai oubliÃ© une dose dâ€™Augmentin ?\",\n",
        "    \"Puis-je prendre deux Pantoprazole si jâ€™ai oubliÃ© la dose dâ€™hier ?\",\n",
        "    \"Combien de jours faut-il pour que lâ€™Augmentin fasse effet ?\",\n",
        "    \"Est-ce que je peux prendre Augmentin avec Pantoprazole ?\",\n",
        "    \"Puis-je boire de lâ€™alcool pendant un traitement Augmentin ?\",\n",
        "    \"Est-ce que le Pantoprazole doit Ãªtre pris avant ou aprÃ¨s le repas ?\",\n",
        "]\n",
        "\n",
        "results = []\n",
        "\n",
        "print(\"\\n==============================\")\n",
        "print(\"ğŸ§ª LANCEMENT DES TESTS\")\n",
        "print(\"==============================\")\n",
        "\n",
        "for q in test_questions:\n",
        "    print(f\"\\nğŸ” QUESTION : {q}\")\n",
        "\n",
        "    r = ask_with_xai(q, final_output, df)\n",
        "\n",
        "    print(\"\\nğŸ¤– RÃ‰PONSE FINALE :\")\n",
        "    print(r[\"answer_final\"])\n",
        "\n",
        "    if r[\"quality_report\"] is not None:\n",
        "        print(\"\\nğŸ“Š SELF-CHECK :\")\n",
        "        print(r[\"quality_report\"])\n",
        "\n",
        "    print(\"\\nğŸ›¡ï¸ NOTE SÃ‰CURITÃ‰ :\", r[\"safety_note\"])\n",
        "\n",
        "    # Sauvegarder rÃ©sultats pour mÃ©triques globales\n",
        "    results.append({\n",
        "        \"question\": q,\n",
        "        \"raw\": r[\"answer_raw\"],\n",
        "        \"final\": r[\"answer_final\"],\n",
        "        \"quality\": r[\"quality_report\"],\n",
        "        \"risk\": r[\"quality_report\"][\"risk\"] if r[\"quality_report\"] else False,\n",
        "        \"invented\": r[\"quality_report\"][\"invented_interaction\"] if r[\"quality_report\"] else False,\n",
        "        \"hallucination\": r[\"quality_report\"][\"hallucination\"] if r[\"quality_report\"] else False,\n",
        "        \"certainty\": int(r[\"quality_report\"][\"certainty\"].replace(\"/100\",\"\")) if r[\"quality_report\"] else 100\n",
        "    })\n",
        "\n",
        "\n",
        "##############################################\n",
        "# ğŸ“Š MÃ‰TRIQUES GLOBALES\n",
        "##############################################\n",
        "\n",
        "print(\"\\n\\n==============================\")\n",
        "print(\"ğŸ“Š MÃ‰TRIQUES GLOBALES DU SYSTÃˆME\")\n",
        "print(\"==============================\")\n",
        "\n",
        "df_eval = pd.DataFrame(results)\n",
        "\n",
        "num = len(df_eval)\n",
        "\n",
        "risk_rate = 100 * df_eval[\"risk\"].sum() / num\n",
        "invented_rate = 100 * df_eval[\"invented\"].sum() / num\n",
        "halluc_rate = 100 * df_eval[\"hallucination\"].sum() / num\n",
        "certainty_avg = df_eval[\"certainty\"].mean()\n",
        "\n",
        "# Score global pondÃ©rÃ©\n",
        "global_score = (\n",
        "    (100 - risk_rate) * 0.5 +\n",
        "    (100 - invented_rate) * 0.3 +\n",
        "    certainty_avg * 0.2\n",
        ")\n",
        "\n",
        "print(df_eval[[\"question\", \"final\", \"certainty\", \"risk\", \"invented\", \"hallucination\"]])\n",
        "\n",
        "print(\"\\nğŸ“Œ NOMBRE DE QUESTIONS :\", num)\n",
        "print(f\"ğŸ“Œ Taux rÃ©ponses Ã  risque (%) : {risk_rate:.1f}\")\n",
        "print(f\"ğŸ“Œ Taux interactions inventÃ©es (%) : {invented_rate:.1f}\")\n",
        "print(f\"ğŸ“Œ Taux hallucinations (%) : {halluc_rate:.1f}\")\n",
        "print(f\"ğŸ“Œ Certitude moyenne (%) : {certainty_avg:.1f}\")\n",
        "print(f\"\\nğŸ† SCORE GLOBAL DE SÃ‰CURITÃ‰ /100 : {global_score:.1f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install pdfplumber"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install langchain\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "pdf reader et pdf chat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "                        PDF\n",
        "                        â”‚\n",
        "                        â–¼\n",
        "                        Extraction du contenu (texte / structure)\n",
        "                        â”‚\n",
        "                        â–¼\n",
        "                        Indexation (chunks + embeddings)\n",
        "                        â”‚\n",
        "                        â–¼\n",
        "                        RAG\n",
        "                        â”‚\n",
        "                        â–¼\n",
        "                        LLM\n",
        "                        â”‚\n",
        "                        â–¼\n",
        "                        RÃ©ponses conversationnelles sur le document\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Import robuste pour LangChain Splitter ---\n",
        "try:\n",
        "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "    print(\"âœ” Import depuis langchain.text_splitter\")\n",
        "except ImportError:\n",
        "    try:\n",
        "        from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "        print(\"âœ” Import depuis langchain_text_splitters\")\n",
        "    except ImportError:\n",
        "        try:\n",
        "            from langchain_core.text_splitter import RecursiveCharacterTextSplitter\n",
        "            print(\"âœ” Import depuis langchain_core.text_splitter\")\n",
        "        except ImportError:\n",
        "            raise ImportError(\n",
        "                \"âŒ Impossible d'importer RecursiveCharacterTextSplitter.\\n\"\n",
        "                \"Installe une version rÃ©cente :\\n\"\n",
        "                \"pip install -U langchain langchain-community langchain-core\"\n",
        "            )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -U langchain langchain-core langchain-community\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import langchain\n",
        "print(langchain.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pdfplumber\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "import httpx\n",
        "from openai import OpenAI\n",
        "import asyncio\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_text_from_pdfs(pdf_paths):\n",
        "    \"\"\"\n",
        "    pdf_paths : liste de chemins PDF\n",
        "    \"\"\"\n",
        "    text = \"\"\n",
        "    for pdf in pdf_paths:\n",
        "        with pdfplumber.open(pdf) as doc:\n",
        "            for page in doc.pages:\n",
        "                content = page.extract_text()\n",
        "                if content:\n",
        "                    text += content + \"\\n\"\n",
        "    return text.strip()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_vector_store(text):\n",
        "    \"\"\"\n",
        "    Transforme le texte PDF en chunks + embeddings + FAISS retriever\n",
        "    \"\"\"\n",
        "\n",
        "    chunks = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=8000,\n",
        "        chunk_overlap=1000\n",
        "    ).split_text(text)\n",
        "\n",
        "    embeddings = HuggingFaceEmbeddings(\n",
        "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "    )\n",
        "\n",
        "    return FAISS.from_texts(chunks, embeddings)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_medical_prompt(question, context):\n",
        "    template = \"\"\"\n",
        "Tu es un assistant mÃ©dical intelligent.\n",
        "\n",
        "RÃ”LE :\n",
        "- Si le document contient des rÃ©sultats mÃ©dicaux : explique leur signification.\n",
        "- Si câ€™est une ordonnance : identifie les mÃ©dicaments et leur usage.\n",
        "- Si câ€™est un rapport : rÃ©sume les conclusions.\n",
        "- Si le texte est administratif : explique les dÃ©marches.\n",
        "- Si le texte est incomplet : donne la meilleure interprÃ©tation possible.\n",
        "\n",
        "âš ï¸ RÃˆGLES :\n",
        "- Pas de spÃ©culation.\n",
        "- Pas dâ€™invention mÃ©dicale.\n",
        "- Utilise uniquement le CONTEXTE fourni.\n",
        "- Si lâ€™information manque â†’ dire \"DonnÃ©e absente du document\".\n",
        "\n",
        "ğŸ“˜ CONTEXTE :\n",
        "{context}\n",
        "\n",
        "â“ QUESTION :\n",
        "{question}\n",
        "\n",
        "ğŸ’¬ RÃ‰PONSE :\n",
        "\"\"\"\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_template(template)\n",
        "    return prompt.format(context=context, question=question)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def call_esprit_llm(prompt, esprit_api_key):\n",
        "    http_client = httpx.Client(verify=False)\n",
        "\n",
        "    client = OpenAI(\n",
        "        api_key=esprit_api_key,\n",
        "        base_url=\"https://tokenfactory.esprit.tn/api\",\n",
        "        http_client=http_client\n",
        "    )\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"hosted_vllm/Llama-3.1-70B-Instruct\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"Tu es un assistant mÃ©dical et administratif utile et concis.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0.4,\n",
        "        max_tokens=700,\n",
        "        top_p=0.9\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyse_pdf_chat(question, pdf_paths, esprit_api_key):\n",
        "    # Extraction du texte PDF\n",
        "    text = extract_text_from_pdfs(pdf_paths)\n",
        "    if not text:\n",
        "        return \"âŒ Aucun texte dÃ©tectÃ© dans les PDF.\"\n",
        "\n",
        "    # CrÃ©ation du store FAISS\n",
        "    vector_store = create_vector_store(text)\n",
        "\n",
        "    retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})\n",
        "    docs = retriever.invoke(question)\n",
        "\n",
        "    if not docs:\n",
        "        return \"âŒ Aucun passage pertinent trouvÃ©.\"\n",
        "\n",
        "    # Context\n",
        "    context = \"\\n\\n\".join([d.page_content for d in docs])\n",
        "\n",
        "    # Prompt intelligent\n",
        "    prompt = build_medical_prompt(question, context)\n",
        "\n",
        "    # Appel API\n",
        "    return call_esprit_llm(prompt, esprit_api_key)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "esprit_api_key = \"sk-e376096028c847389e18f6d1f650be93\"\n",
        "\n",
        "question = \"Explique les rÃ©sultats de cette ordonnance.\"\n",
        "pdf_paths = [\"C:\\\\Users\\\\hp\\\\Desktop\\\\4Ã¨me\\\\projet\\\\zahrouni maya.pdf\"]\n",
        "\n",
        "response = analyse_pdf_chat(question, pdf_paths, esprit_api_key)\n",
        "print(\"\\nğŸ§  RÃ‰PONSE :\\n\")\n",
        "print(response)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pdfplumber\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "# --- Extraire texte depuis un PDF ---\n",
        "def extract_text_from_pdf(path):\n",
        "    text = \"\"\n",
        "    with pdfplumber.open(path) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            page_text = page.extract_text()\n",
        "            if page_text:\n",
        "                text += page_text + \"\\n\"\n",
        "    return text.strip()\n",
        "\n",
        "# --- Construire le vector store ---\n",
        "def create_vector_store_from_text(text):\n",
        "    splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=2000,\n",
        "        chunk_overlap=300\n",
        "    )\n",
        "    \n",
        "    chunks = splitter.split_text(text)\n",
        "    \n",
        "    embedding_model = HuggingFaceEmbeddings(\n",
        "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "    )\n",
        "    \n",
        "    vector_store = FAISS.from_texts(chunks, embedding_model)\n",
        "    return vector_store\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pdf_path = r\"C:\\Users\\hp\\Desktop\\4Ã¨me\\projet\\zahrouni maya.pdf\"\n",
        "\n",
        "# 1. Extraction texte\n",
        "pdf_text = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "# 2. Construction vector store\n",
        "vector_store = create_vector_store_from_text(pdf_text)\n",
        "\n",
        "print(\"âœ” vector_store crÃ©Ã© avec succÃ¨s\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def xai_self_check(question, answer, context, esprit_api_key):\n",
        "    prompt = f\"\"\"\n",
        "Tu es un expert en Ã©valuation RAG et sÃ©curitÃ© mÃ©dicale.\n",
        "Analyse la rÃ©ponse du modÃ¨le STRICTEMENT selon le contexte fourni.\n",
        "\n",
        "Donne un JSON STRICT avec les champs suivants :\n",
        "\n",
        "{{\n",
        " \"faithfulness\": 0,\n",
        " \"relevance\": 0,\n",
        " \"completeness\": 0,\n",
        " \"risk\": false,\n",
        " \"errors\": [],\n",
        " \"final_score\": 0\n",
        "}}\n",
        "\n",
        "DÃ©finitions :\n",
        "\n",
        "- \"faithfulness\" = 1 si la rÃ©ponse correspond STRICTEMENT au contexte PDF, sinon 0.\n",
        "- \"relevance\" = score 0 Ã  100 de pertinence par rapport Ã  la question.\n",
        "- \"completeness\" = 1 si la rÃ©ponse inclut toutes les infos du contexte nÃ©cessaires.\n",
        "- \"risk\" = true si la rÃ©ponse peut Ãªtre dangereuse, fausse, ou spÃ©culative.\n",
        "- \"errors\" = liste dÃ©taillÃ©e des hallucinations ou contradictions.\n",
        "- \"final_score\" = score pondÃ©rÃ© :  \n",
        "      50% faithfulness + 30% relevance + 20% completeness.\n",
        "\n",
        "ğŸ“˜ CONTEXTE PDF :\n",
        "{context}\n",
        "\n",
        "â“ QUESTION :\n",
        "{question}\n",
        "\n",
        "ğŸ’¬ RÃ‰PONSE DU MODÃˆLE :\n",
        "{answer}\n",
        "\n",
        "RÃ©pond uniquement en JSON.\n",
        "    \"\"\"\n",
        "\n",
        "    http_client = httpx.Client(verify=False)\n",
        "    client = OpenAI(\n",
        "        api_key=esprit_api_key,\n",
        "        base_url=\"https://tokenfactory.esprit.tn/api\",\n",
        "        http_client=http_client\n",
        "    )\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"hosted_vllm/Llama-3.1-70B-Instruct\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0,\n",
        "        max_tokens=500\n",
        "    )\n",
        "\n",
        "    raw = response.choices[0].message.content.strip()\n",
        "\n",
        "    # nettoyage fallback\n",
        "    try:\n",
        "        return json.loads(raw)\n",
        "    except:\n",
        "        print(\"âš ï¸ JSON invalide retournÃ©, affichage brut :\")\n",
        "        print(raw)\n",
        "        return {\n",
        "            \"faithfulness\": 0,\n",
        "            \"relevance\": 0,\n",
        "            \"completeness\": 0,\n",
        "            \"risk\": True,\n",
        "            \"errors\": [\"Invalid JSON from LLM\", raw],\n",
        "            \"final_score\": 0\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyse_pdf_chat(question, pdf_text, vector_store, esprit_api_key):\n",
        "    # Retrieve context from vector store\n",
        "    try:\n",
        "        docs = vector_store.similarity_search(question, k=3)\n",
        "        context = \"\\n\\n\".join([d.page_content for d in docs])\n",
        "    except:\n",
        "        context = pdf_text\n",
        "\n",
        "    # Build prompt\n",
        "    prompt = f\"\"\"\n",
        "Tu es un assistant mÃ©dical intelligent.\n",
        "Analyse ces informations :\n",
        "\n",
        "ğŸ“˜ CONTEXTE :\n",
        "{context}\n",
        "\n",
        "â“ QUESTION :\n",
        "{question}\n",
        "\n",
        "RÃ©ponse claire et concise :\n",
        "\"\"\"\n",
        "\n",
        "    # Call ESPRIT API\n",
        "    http_client = httpx.Client(verify=False)\n",
        "    client = OpenAI(\n",
        "        api_key=esprit_api_key,\n",
        "        base_url=\"https://tokenfactory.esprit.tn/api\",\n",
        "        http_client=http_client\n",
        "    )\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"hosted_vllm/Llama-3.1-70B-Instruct\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.4,\n",
        "        max_tokens=400\n",
        "    )\n",
        "\n",
        "    answer = response.choices[0].message.content.strip()\n",
        "\n",
        "    return answer, context\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_and_evaluate(question, pdf_text, vector_store, esprit_api_key):\n",
        "    print(\"\\n==============================\")\n",
        "    print(f\"ğŸ§  QUESTION : {question}\")\n",
        "    print(\"==============================\")\n",
        "\n",
        "    # --- 1. Get RAG answer\n",
        "    answer, context = analyse_pdf_chat(question, pdf_text, vector_store, esprit_api_key)\n",
        "\n",
        "    print(\"\\nğŸ¤– RÃ‰PONSE DU MODÃˆLE :\\n\")\n",
        "    print(answer)\n",
        "\n",
        "    # --- 2. Evaluate answer with XAI\n",
        "    evaluation = xai_self_check(question, answer, context, esprit_api_key)\n",
        "\n",
        "    print(\"\\nğŸ“Š RAPPORT XAI :\")\n",
        "    print(evaluation)\n",
        "\n",
        "    return {\n",
        "        \"question\": question,\n",
        "        \"answer\": answer,\n",
        "        \"context\": context,\n",
        "        \"evaluation\": evaluation\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "esprit_api_key = \"sk-e376096028c847389e18f6d1f650be93\"\n",
        "\n",
        "question = \"Explique les rÃ©sultats de cette ordonnance.\"\n",
        "\n",
        "result = test_and_evaluate(question, pdf_text, vector_store, esprit_api_key)\n",
        "\n",
        "print(\"\\nğŸ‰ RÃ‰SUMÃ‰ FINAL :\")\n",
        "print(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pdfplumber\n",
        "import json\n",
        "import httpx\n",
        "from openai import OpenAI\n",
        "\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_text_from_pdf(path):\n",
        "    text = \"\"\n",
        "    with pdfplumber.open(path) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            t = page.extract_text()\n",
        "            if t:\n",
        "                text += t + \"\\n\"\n",
        "    return text.strip()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_vector_store(text):\n",
        "    splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=1500,\n",
        "        chunk_overlap=150\n",
        "    )\n",
        "    chunks = splitter.split_text(text)\n",
        "\n",
        "    embeddings = HuggingFaceEmbeddings(\n",
        "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "    )\n",
        "\n",
        "    vs = FAISS.from_texts(chunks, embeddings)\n",
        "    return vs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_medical_analysis_prompt(question, context):\n",
        "\n",
        "    return f\"\"\"\n",
        "Tu es un assistant mÃ©dical ultra-fiable spÃ©cialisÃ© dans lâ€™analyse de documents biologiques.\n",
        "\n",
        "Tu dois rÃ©pondre STRICTEMENT Ã  partir du texte fourni.\n",
        "Aucune connaissance extÃ©rieure nâ€™est autorisÃ©e.\n",
        "\n",
        "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "ğŸ“„ CONTEXTE (DonnÃ©es du document)\n",
        "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "{context}\n",
        "\n",
        "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "âš ï¸ RÃˆGLES ANTI-HALLUCINATION\n",
        "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "1. Ne JAMAIS interprÃ©ter sans comparer aux valeurs normales prÃ©sentes dans le document.\n",
        "2. Ne JAMAIS Ã©crire des phrases comme : â€œpeut indiquerâ€, â€œprobablementâ€, â€œinfectionâ€, â€œinflammationâ€.\n",
        "3. Ne PAS inventer de diagnostic ou de maladie.\n",
        "4. Si une information n'est pas dans le document â†’ Ã©crire : â€œNon indiquÃ© dans le document.â€\n",
        "5. RÃ©ponse courte, factuelle et maximum 8 lignes.\n",
        "6. Ne pas rÃ©Ã©crire tout le document.\n",
        "\n",
        "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "â“ QUESTION UTILISATEUR\n",
        "{question}\n",
        "\n",
        "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "ğŸ§ª RÃ‰PONSE FACTUELLE (basÃ©e EXCLUSIVEMENT sur le document) :\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ask_llm(prompt):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"hosted_vllm/Llama-3.1-70B-Instruct\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"Assistant mÃ©dical strictement factuel.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        max_tokens=500,\n",
        "        temperature=0.0\n",
        "    )\n",
        "    return response.choices[0].message.content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_answer(context, answer):\n",
        "    errors = []\n",
        "\n",
        "    # FAITHFULNESS = vÃ©rifier si les phrases ne sortent pas du contexte\n",
        "    faithfulness = 100 if answer.lower() in context.lower() or any(w in context.lower() for w in answer.lower().split()) else 0\n",
        "\n",
        "    # RELEVANCE = question pertinente par rapport au document\n",
        "    relevance = 100 if len(set(answer.split()) & set(context.split())) > 5 else 60\n",
        "\n",
        "    # COMPLETENESS = la rÃ©ponse couvre-t-elle les valeurs Ã©voquÃ©es\n",
        "    completeness = 100 if \"mm\" in answer or \"g/l\" in answer or \"%\" in answer else 0\n",
        "\n",
        "    # RISK = contient-il des mots mÃ©dicaux dangereux ?\n",
        "    risky_words = [\"infection\", \"inflammation\", \"maladie\", \"insuffisance\", \"risque\", \"grave\"]\n",
        "    risk = any(w in answer.lower() for w in risky_words)\n",
        "\n",
        "    return {\n",
        "        \"faithfulness\": faithfulness,\n",
        "        \"relevance\": relevance,\n",
        "        \"completeness\": completeness,\n",
        "        \"risk\": risk,\n",
        "        \"errors\": errors,\n",
        "        \"final_score\": (faithfulness*0.4 + relevance*0.3 + completeness*0.3)\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyse_pdf_chat(question, pdf_path):\n",
        "    text = extract_text_from_pdf(pdf_path)\n",
        "    vector_store = create_vector_store(text)\n",
        "\n",
        "    docs = vector_store.similarity_search(question, k=4)\n",
        "    context = \"\\n\\n\".join([d.page_content for d in docs])\n",
        "\n",
        "    prompt = build_medical_analysis_prompt(question, context)\n",
        "    answer = ask_llm(prompt)\n",
        "\n",
        "    eval_report = evaluate_answer(context, answer)\n",
        "\n",
        "    return {\n",
        "        \"question\": question,\n",
        "        \"answer\": answer,\n",
        "        \"context_used\": context,\n",
        "        \"evaluation\": eval_report\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pdf_path = r\"C:\\Users\\hp\\Desktop\\4Ã¨me\\projet\\zahrouni maya.pdf\"\n",
        "question = \"Explique les rÃ©sultats de cette ordonnance.\"\n",
        "\n",
        "result = analyse_pdf_chat(question, pdf_path)\n",
        "\n",
        "print(\"\\nğŸ§  RÃ‰PONSE :\\n\", result[\"answer\"])\n",
        "print(\"\\nğŸ“Š RAPPORT XAI :\\n\", result[\"evaluation\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "questions = [\n",
        "    \"Explique les globules rouges.\",\n",
        "    \"Y a-t-il des anomalies dans la NFS ?\",\n",
        "    \"La crÃ©atinine est-elle normale ?\",\n",
        "    \"RÃ©sumÃ© de toute lâ€™analyse.\"\n",
        "]\n",
        "\n",
        "for q in questions:\n",
        "    print(\"\\n==============================\")\n",
        "    print(\"ğŸ§  QUESTION :\", q)\n",
        "    print(\"==============================\")\n",
        "\n",
        "    result = analyse_pdf_chat(q, pdf_path)\n",
        "\n",
        "    print(\"\\nğŸ¤– RÃ‰PONSE :\\n\", result[\"answer\"])\n",
        "    print(\"\\nğŸ“Š XAI :\\n\", result[\"evaluation\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu"
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00eef88e47714b38a07b34b73108c6a9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0192bafdd617471cb5f6be8dcd512bce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88c1ce2ddd064fbe85a586576fe493fa",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e645994122fc461f819846023dcd2ba9",
            "value": "model-00003-of-00003.safetensors:â€‡100%"
          }
        },
        "0b00d21b6abb46009f6db9a1c8d54dfc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c5fe4964ba044418d1941d726f797fb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c636ff3de1b4d5db8abfad4880c6c5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54af3105557b44a49967ee8601c22cc3",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f648686157874b5e98d0e2c128a8b0a1",
            "value": "Fetchingâ€‡3â€‡files:â€‡100%"
          }
        },
        "1d47491716fe4f08a0499c8c8c277ce8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d14b340d100947b9888fdcec42980c58",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5ffee3e67ae5419a920c4a3bd5d27f16",
            "value": "generation_config.json:â€‡100%"
          }
        },
        "218ad0cbbe3b41918dfaf60772cbe8fc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2219dbba4f1044cea2d08bb03d6b18cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a0f91274b164edbb6e1c108d3036c2e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_db3f1d0c5936403b8191543a9b7a1829",
            "value": "model.safetensors.index.json:â€‡"
          }
        },
        "296027a7457e4f6caa8c32eb8674b444": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b72dc49701842339e9f78c6117d8b3f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37027262ca8f45fca762fcf92dea17d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b72dc49701842339e9f78c6117d8b3f",
            "max": 4540516344,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ed7527d51040465a8726800dc3c01007",
            "value": 4540516344
          }
        },
        "3a58f093641745bc8681b26e4c7fabe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86de02612f8e44b782f18af25e6a4106",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_49b6b40ec7f6491c93a3123a90e1ccef",
            "value": 3
          }
        },
        "3af90978ba8a498fb98b8608f9cd2ae7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cd575ad898d4600846302fecc037de4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3af90978ba8a498fb98b8608f9cd2ae7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ebae88c6922b4fde91f0d5eac0d7f750",
            "value": "model-00001-of-00003.safetensors:â€‡100%"
          }
        },
        "40496169501e42ba825f99e0926534b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "416c77e1289d4a9bb7c8c64b2caeb892": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "444ef842b3954a7ba7ccd2816d8c1d31": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47096b2ddfe0413abbbbf7d62b5fdd90": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9052926bef404f31be13f16b50c7f21e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_4fc8dd04f90247b3b1cc675e9afe86e6",
            "value": "â€‡111/111â€‡[00:00&lt;00:00,â€‡12.9kB/s]"
          }
        },
        "4797a2e381a04cacbde2bf4f7224b88b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83dd60b1995040ed98d939e3ba058f3d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d18e8eaca36441309fb1ad398c639ac8",
            "value": "â€‡3/3â€‡[03:53&lt;00:00,â€‡97.85s/it]"
          }
        },
        "485c63048c3b48ec964b5d5f0cd084fc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49b6b40ec7f6491c93a3123a90e1ccef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4fc8dd04f90247b3b1cc675e9afe86e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "531540e43a1f4a59a7d3c1248b053b6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2b7c17938c44127aaccbd0dde9b54ca",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_93a69b11ca3b4487995f1065f7f0ab0a",
            "value": 1
          }
        },
        "535353b6b5be4f5dbf185e5bbaed2ef1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5975db4b518447b8b41842a1eb644597",
              "IPY_MODEL_3a58f093641745bc8681b26e4c7fabe3",
              "IPY_MODEL_b8d6c8d3f5f34ba9aa5a59d3d01954f7"
            ],
            "layout": "IPY_MODEL_218ad0cbbe3b41918dfaf60772cbe8fc"
          }
        },
        "54af3105557b44a49967ee8601c22cc3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57f9a0c60ea048ba8937a67371d010d0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5975db4b518447b8b41842a1eb644597": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90e25c069914413fbc48c806ad1d231f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_7d9cd8ee5c4d48eb89d204f847069a11",
            "value": "Loadingâ€‡checkpointâ€‡shards:â€‡100%"
          }
        },
        "5a1159930b7347aaa7f5bf15a72d91cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00eef88e47714b38a07b34b73108c6a9",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5e2808d061a745d3aaabdac845002d91",
            "value": "â€‡25.1k/?â€‡[00:00&lt;00:00,â€‡644kB/s]"
          }
        },
        "5d76a705dbb540fdb1179ac584c5ff96": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5e2808d061a745d3aaabdac845002d91": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ffee3e67ae5419a920c4a3bd5d27f16": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6568006d754f41a286f8fad7aa2985b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ec5911c0c48420180aa00b46d0c617a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_444ef842b3954a7ba7ccd2816d8c1d31",
            "value": "model-00002-of-00003.safetensors:â€‡100%"
          }
        },
        "6b69f85797e443e8839d0cd6fceb94b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_daa9b7676ec54298ad9151cb24a84ac1",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_cb247b4159cd480b9b6cf3c1a2097820",
            "value": "â€‡4.54G/4.54Gâ€‡[03:34&lt;00:00,â€‡51.6MB/s]"
          }
        },
        "6ec5911c0c48420180aa00b46d0c617a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7326bd00f23f41d0a71aa241a8a2bb41": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "763ec22d5d3a4bdc9fe7e0e013bcb2e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a8732ebdc7d4a7cbf8eedfef39ba4b1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d9cd8ee5c4d48eb89d204f847069a11": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83dd60b1995040ed98d939e3ba058f3d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86de02612f8e44b782f18af25e6a4106": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88c1ce2ddd064fbe85a586576fe493fa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c80c28c04484fc5aad7e5d951e354f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6568006d754f41a286f8fad7aa2985b7",
              "IPY_MODEL_baed9bdb4a624989b32ae5e1186f2157",
              "IPY_MODEL_f6131e2dff014161906d6b529488d489"
            ],
            "layout": "IPY_MODEL_485c63048c3b48ec964b5d5f0cd084fc"
          }
        },
        "9052926bef404f31be13f16b50c7f21e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90e25c069914413fbc48c806ad1d231f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92ec5ad0732140e99c4c909f335aa0a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2219dbba4f1044cea2d08bb03d6b18cc",
              "IPY_MODEL_531540e43a1f4a59a7d3c1248b053b6b",
              "IPY_MODEL_5a1159930b7347aaa7f5bf15a72d91cc"
            ],
            "layout": "IPY_MODEL_57f9a0c60ea048ba8937a67371d010d0"
          }
        },
        "93a69b11ca3b4487995f1065f7f0ab0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9a0f91274b164edbb6e1c108d3036c2e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f05898dc8a0468396ffcdbde1daea23": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aec44712deb948f780805c56f165267f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afc917ced5044130bec079fe8c2bfa17": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b8d6c8d3f5f34ba9aa5a59d3d01954f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed60fd0371574b72bc4218952115cf14",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c7b931527fa5471b9a56bd159347c33d",
            "value": "â€‡3/3â€‡[01:10&lt;00:00,â€‡23.11s/it]"
          }
        },
        "baed9bdb4a624989b32ae5e1186f2157": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aec44712deb948f780805c56f165267f",
            "max": 4999819336,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7326bd00f23f41d0a71aa241a8a2bb41",
            "value": 4999819336
          }
        },
        "bea35dae283c4466ba98ec5bf09d7573": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5ce626fa3784c0b99af3971e834ec92",
            "max": 111,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cca1b2e67092491a8dd49628ca9f9cef",
            "value": 111
          }
        },
        "c379c82364f54e3e8e423d87259b6f07": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7b931527fa5471b9a56bd159347c33d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb247b4159cd480b9b6cf3c1a2097820": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cca1b2e67092491a8dd49628ca9f9cef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d14b340d100947b9888fdcec42980c58": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d18e8eaca36441309fb1ad398c639ac8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d26c1c00d4e24b549ad4c3d49e9102ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c379c82364f54e3e8e423d87259b6f07",
            "max": 4943162336,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5d76a705dbb540fdb1179ac584c5ff96",
            "value": 4943162336
          }
        },
        "d2b7c17938c44127aaccbd0dde9b54ca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "d40f26a593df41368cb5484b5226ddf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0192bafdd617471cb5f6be8dcd512bce",
              "IPY_MODEL_37027262ca8f45fca762fcf92dea17d1",
              "IPY_MODEL_6b69f85797e443e8839d0cd6fceb94b3"
            ],
            "layout": "IPY_MODEL_9f05898dc8a0468396ffcdbde1daea23"
          }
        },
        "d447cad218a34dfdaa40f5b5aa587aea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1d47491716fe4f08a0499c8c8c277ce8",
              "IPY_MODEL_bea35dae283c4466ba98ec5bf09d7573",
              "IPY_MODEL_47096b2ddfe0413abbbbf7d62b5fdd90"
            ],
            "layout": "IPY_MODEL_416c77e1289d4a9bb7c8c64b2caeb892"
          }
        },
        "d479d6a256ce4ef2a9f516829a5ec835": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "daa9b7676ec54298ad9151cb24a84ac1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db3f1d0c5936403b8191543a9b7a1829": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4a39d84eb754d2abad918ac1268797f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b00d21b6abb46009f6db9a1c8d54dfc",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_763ec22d5d3a4bdc9fe7e0e013bcb2e6",
            "value": "â€‡4.94G/4.94Gâ€‡[03:43&lt;00:00,â€‡41.3MB/s]"
          }
        },
        "e5ce626fa3784c0b99af3971e834ec92": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e645994122fc461f819846023dcd2ba9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6540cd6b53a4814b4e3b5c3a52aa013": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c5fe4964ba044418d1941d726f797fb",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_afc917ced5044130bec079fe8c2bfa17",
            "value": 3
          }
        },
        "e8d557d1c480405da7e56d58ed6fa230": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3cd575ad898d4600846302fecc037de4",
              "IPY_MODEL_d26c1c00d4e24b549ad4c3d49e9102ab",
              "IPY_MODEL_e4a39d84eb754d2abad918ac1268797f"
            ],
            "layout": "IPY_MODEL_296027a7457e4f6caa8c32eb8674b444"
          }
        },
        "ebae88c6922b4fde91f0d5eac0d7f750": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed60fd0371574b72bc4218952115cf14": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed7527d51040465a8726800dc3c01007": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "efefce6cdded49ccb98945a70cd23da9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1c636ff3de1b4d5db8abfad4880c6c5d",
              "IPY_MODEL_e6540cd6b53a4814b4e3b5c3a52aa013",
              "IPY_MODEL_4797a2e381a04cacbde2bf4f7224b88b"
            ],
            "layout": "IPY_MODEL_d479d6a256ce4ef2a9f516829a5ec835"
          }
        },
        "f6131e2dff014161906d6b529488d489": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a8732ebdc7d4a7cbf8eedfef39ba4b1",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_40496169501e42ba825f99e0926534b5",
            "value": "â€‡5.00G/5.00Gâ€‡[03:53&lt;00:00,â€‡134MB/s]"
          }
        },
        "f648686157874b5e98d0e2c128a8b0a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
